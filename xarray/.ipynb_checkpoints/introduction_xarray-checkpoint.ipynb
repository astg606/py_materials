{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://github.com/astg606/py_materials/blob/master/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1><font color=\"red\" size=\"+3\">Introduction to Xarray</font></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "  <head> </head>\n",
    "  <body>\n",
    "<script src=\"https://bot.voiceatlas.mysmce.com/v1/chatlas.js\"></script>\n",
    "<app-chatlas\n",
    "\tatlas-id=\"f759a188-f8bb-46bb-9046-3b1b961bd6aa\"\n",
    "\twidget-background-color=\"#3f51b5ff\"\n",
    "\twidget-text-color=\"#ffffffff\"\n",
    "\twidget-title=\"Chatlas\">\n",
    "</app-chatlas>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Useful References</font>\n",
    "- <a href=\"http://xarray.pydata.org/en/stable/\"> xarray</a>\n",
    "- <a href=\"http://gallery.pangeo.io/repos/pangeo-data/pangeo-tutorial-gallery/xarray.html\"> XARRAY TUTORIAL</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\"> xarray: N-D labeled arrays and datasets in Python</a>\n",
    "- <a href=\"https://nbviewer.jupyter.org/github/mccrayc/tutorials/blob/master/2_reanalysis/CFSR_Data_Tutorial.ipynb\">Importing and mapping reanalysis data with xarray and cartopy</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\">xarray: N-D labeled Arrays and Datasets in Python</a>\n",
    "- <a href=\"https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/use-netcdf-in-python-xarray/\">How to Open and Process NetCDF 4 Data Format in Open Source Python</a>\n",
    "- <a href=\"https://cbrownley.wordpress.com/tag/xarray/\">Visualizing Global Land Temperatures in Python with scrapy, xarray, and cartopy</a>\n",
    "- [Compare weighted and unweighted mean temperature](http://xarray.pydata.org/en/stable/examples/area_weighted_temperature.html)\n",
    "- [Example Weighted/masked average](https://nordicesmhub.github.io/NEGI-Abisko-2019/training/Example_model_global_arctic_average.html)\n",
    "- [Xarray Development Roadmap](http://xarray.pydata.org/en/stable/roadmap.html)\n",
    "- [Xarray Introduction and Tutorial](https://boisestate.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=a38a2efc-1ac6-4c02-af0f-acfc015e9444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_logo](http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png)\n",
    "Image Source: xarray.pydata.org\n",
    "\n",
    "## <font color=\"red\">What is Xarray?</font>\n",
    "+ `Xarray` is an open source project and Python package that makes working with **labeled multi-dimensional arrays** simple and efficient.\n",
    "+ Introduces labels in the form of dimensions, coordinates and attributes on top of raw `NumPy`-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. \n",
    "+ Is inspired by and borrows heavily from `Pandas`.\n",
    "+ Builds on top of, and seamlessly interoperates with, the core scientific Python packages, such as NumPy, SciPy, Matplotlib, and Pandas\n",
    "+ Is particularly tailored to working with `netCDF` files and integrates tightly with `Dask` for parallel computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Implementation and Architecture</font>\n",
    "- NetCDF forms the basis of the Xarray data model and provides a natural and portable serialization format. \n",
    "- Xarray features two main data structures (like `Pandas`): \n",
    "     - **DataArray** xarray’s implementation of a labeled, multi-dimensional array. It has several key properties:\n",
    "          - *data*: N-dimensional array (NumPy or dask) holding the array's values,\n",
    "          - *coords*: dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dimension names for each axis [e.g., (‘time’, ‘latitude’, ‘longitude’)],\n",
    "          - *attrs*: OrderedDict holding arbitrary metadata (e.g. units or descriptions), and\n",
    "          - *name*: an arbitrary name for the array.\n",
    "     - **Dataset**: xarray’s multi-dimensional equivalent of a DataFrame. It is a dict-like container of labeled arrays (DataArrays) with aligned dimensions. It is designed as an in-memory representation of a netCDF dataset. In addition to the dict-like interface of the dataset itself, which can be used to access any DataArray in a Dataset, datasets have four key properties:\n",
    "          - *data_vars*: OrderedDict of DataArray objects corresponding to data variables,\n",
    "          - *coords*: OrderedDict of DataArray objects intended to label points used in data_vars (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dictionary mapping from dimension names to the fixed length of each dimension (e.g., {‘x’: 6, ‘y’: 6, ‘time’: 8}), and\n",
    "          - *attrs*: OrderedDict to hold arbitrary metadata pertaining to the dataset.\n",
    "\n",
    "![fig_structure](https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/jors-5-148-g2.png)\n",
    "Image Source: openresearchsoftware.metajnl.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Core Xarray Features</font>\n",
    "\n",
    "- <u>*Serialization and I/O*</u>: xarray supports direct serialization and I/O to several file formats including pickle, netCDF, OPeNDAP (read-only), GRIB1/2 (read-only), and HDF by integrating with third-party libraries.\n",
    "- <u>*Metadata*</u>: Keep track of arbitrary metadata in the form of a Python dictionary. `x.attrs`.\n",
    "- <u>*Label-based indexing*</u>: Similarly to Pandas objects, xarray objects support both integer- and label-based lookups along each dimension. However, xarray objects also have named dimensions, so you can optionally use dimension names instead of relying on the positional ordering of dimensions. `x.loc['2014-01-01']` or `x.sel(time='2014-01-01')`\n",
    "- <u>*Arithmetic*</u>: arithmetic between xarray objects vectorizes based on dimension names, automatically looping (broadcasting) over each distinct dimension. This eliminates the need to insert dummy dimensions of size one to facilitate broadcasting, a common pattern with NumPy.\n",
    "- <u>*Aggregation*</u>: calculation of statistics (e.g. sum) along a dimension of an xarray object can be done by dimension name instead of an integer axis number. `x.sum('time')`\n",
    "- <u>*Plotting*</u>: Plotting functionality is a thin wrapper around Matplotlib. The syntax and function names from Matplotlib are used whenever possible, resulting in a seamless transition between the two.\n",
    "- <u>*Missing Data*</u>: Are smoothly handled in all operations, including arithmetic, alignment and aggregation.\n",
    "- <u>*Interactivity with Pandas*</u>: xarray objects seamlessly to convert to and from pandas objects to interact with the rest of the PyData ecosystem.\n",
    "- <u>*Out-of-core computation*</u>: xarray’s data structures can be backed by dask to support parallel and streaming computation on data that does not fit into memory, up to 100s of GB or TBs in size. \n",
    "- <u>*Alignment*</u>: Support of  database-like join operations for combining xarray objects along common coordinates.\n",
    "- <u>*Split-apply-combine*</u>: xarray includes N-dimensional grouped operations implementing the split-apply-combine strategy. `x.groupby('time.dayofyear').mean()`\n",
    "- <u>*Resampling and rolling window operations*</u>: Utilizing the efficient resampling methods from Pandas and rolling window operations from Bottleneck, xarray offers a robust set of resampling and rolling window operations along a single dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Supported File Types</font>\n",
    "\n",
    "`Xarray`  supports direct serialization and IO to several [file formats](https://docs.xarray.dev/en/stable/user-guide/io.html) including:\n",
    "\n",
    "- Pickle\n",
    "- netCDF 3/4 format (recommended)\n",
    "- RaterIO\n",
    "- Zarr: a Python package providing an implementation of chunked, compressed, N-dimensional arrays. Zarr has the ability to store arrays in a range of ways, including in memory, in files, and in cloud-based object storage such as Amazon S3 and Google Cloud Storage. \n",
    "- GRIB format: thereading of GRIB files is done using the ECMWF `cgrib` Python driver (`engine='cfgrib'` as argument of `open_dataset`).\n",
    "- Xarray can read GRIB, HDF4 and other file formats supported by PyNIO (`engine='pynio'` as argument of `open_dataset`).\n",
    "- Xarray can also read HDF5 files (using netCDF4 first) but can only access variables within groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color='red'> Only run the following cell if you are on Google Colab</font>\n",
    "\n",
    "Uncomment the cell below if you are on Google Colab. Unfortunately this might no longer work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get install libproj-dev proj-data proj-bin\n",
    "#!apt-get install libgeos-dev\n",
    "#!pip install cython\n",
    "#!pip install cartopy\n",
    "#!pip install netCDF4\n",
    "#!pip install xarray==0.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Version of Numpy:   {np.__version__}\")\n",
    "print(f\"Version of Pandas:  {pd.__version__}\")\n",
    "print(f\"Version of netCDF4: {netCDF4.__version__}\")\n",
    "print(f\"Version of Xarray:  {xr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Basic Manipulations</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Xarray DataArray</font>\n",
    "\n",
    "- Xarray’s implementation of a labeled, multi-dimensional array.\n",
    "- Has several key properties:\n",
    "    - `values`: a numpy.ndarray holding the array’s values\n",
    "    - `dims`: dimension names for each axis (e.g., `('time', 'lat', 'lon')`)\n",
    "    - `coords`: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)\n",
    "    - `attrs`: dict to hold arbitrary metadata (attributes)\n",
    "    \n",
    "- Xarray uses `dims` and `coords` to enable its core metadata aware operations. \n",
    "- Dimensions provide names that xarray uses instead of the `axis` argument found in many Numpy functions. \n",
    "- Coordinates enable fast label based indexing and alignment, building on the functionality of the `index` found on a Pandas `DataFrame` or `Series`.\n",
    "\n",
    "Assume that we have several time records of a two dimensional surface temperature field. It can be represented as:\n",
    "\n",
    "$$T(x,y,t)$$\n",
    "\n",
    "where `x` and  `y` are spatial dimensions and and `t` is time. \n",
    "We want to create a Xarray object to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a DataArray**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a 3D Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntimes = 7\n",
    "nlats = 5\n",
    "nlons = 6\n",
    "max_val, min_val = 1.0, -1.0\n",
    "range_size = (max_val - min_val)\n",
    "np_data = 273.5 + 10 * \n",
    "          (range_size*np.random.randn(ntimes, nlats, nlons) + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data type:  \\n\\t {type(np_data)}\")\n",
    "print(f\"Data shape: \\n\\t {np_data.shape}\")\n",
    "print(f\"Numpy array: \\n {np_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic `DataArray` by passing it just a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Type: \\n\\t {type(xr_data)}\")\n",
    "print(f\"Xarray DataArray: \\n {xr_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Xarray` generates some basic dimension names for us: `dim_0`, `dim_1`, `dim_2`.\n",
    "- We can also pass in our own dimension names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data, dims=['time', 'lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have named each of the dimensions.\n",
    "- We can take arrays representing the values for the coordinates for each of these dimensions and associate them with the data when we create the `DataArray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the values of the data array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xr_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dimension labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of the dimensions:\n",
    "\n",
    "- `Xarray` sets default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us include the coordinates.\n",
    "\n",
    "Use `Pandas` to create an array of datetimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range('2010-01-01', freq='12H', periods=ntimes)\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and longitude points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.linspace(-120, -60, nlons)\n",
    "lats = np.linspace(30, 65, nlats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the time, latitude and longitude values to include the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data, \n",
    "                       coords=[times, lats, lons], \n",
    "                       dims=['time', 'lat', 'lon'])\n",
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get again the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data['time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes\n",
    "\n",
    "- We can add metadata attributes that can be use later for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs['short_name'] = 'T'\n",
    "xr_data.attrs['long_name'] = 'surface_air_temperature'\n",
    "xr_data.attrs['units'] = 'K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add metadata to coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "xr_data.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "xr_data.lon.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "xr_data.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "xr_data.lat.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.attrs[\"long_name\"] = \"time\"\n",
    "xr_data.time.attrs[\"units\"] = \"Hours since 2010-01-01 00:00:00\"\n",
    "xr_data.time.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Exercise</font>\n",
    "\n",
    "We want to create a DataArray (`surf_data`) that has the surface pressure data:\n",
    "\n",
    "- The data values are in a Numpy array with $30 \\times 25$ grid points. \n",
    "    - All the values are initialized to 965.7.\n",
    "    - The attribute units is `mb`.\n",
    "    - The attribute long_name is `surface pressure` and the one for short_name is `sp'.\n",
    "    - The valid_range attribute is `[550.0, 1525.0]`.\n",
    "    - The missing_value attribute is `-9999.0'.\n",
    "- The latitudes (25) and longitudes (30) cover the entire globe.\n",
    "    - The latitude and longitude attribute units are `degrees_north` and `degrees_east` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<p>\n",
    "\n",
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "```python\n",
    "nlons = 30\n",
    "nlats = 25\n",
    "init_val = 967.5\n",
    "\n",
    "lats = np.linspace(-90, 90, nlats)\n",
    "lons = np.linspace(-180, 180, nlons) \n",
    "surf_pres = xr.DataArray(np.full((nlats, nlons), init_val), \n",
    "                       coords=[lats, lons], \n",
    "                       dims=['lat', 'lon'])\n",
    "\n",
    "surf_pres.attrs['short_name'] = 'sp'\n",
    "surf_pres.attrs['long_name'] = 'surface_pressure'\n",
    "surf_pres.attrs['units'] = 'mb'\n",
    "surf_pres.attrs['missing_value'] = -9999.0\n",
    "surf_pres.attrs['valid_range'] = [550.0, 1525.0]\n",
    "    \n",
    "surf_pres.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "surf_pres.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "\n",
    "surf_pres.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "surf_pres.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing**\n",
    "\n",
    "- Xarray supports four kinds of indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional and by integer label, like Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xr_data[:,2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` or \"location\": positional and coordinate label, like Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.loc[:,47.5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isel` or \"integer select\":  \n",
    "\n",
    "- By dimension name and integer label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.isel(lat=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sel` or \"select for label-based indexing\": \n",
    "\n",
    "- By dimension name and coordinate label.\n",
    "- Allow us to fetch values based on the value of the coordinate, not the numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike positional indexing, label-based indexing frees us from having to know how our array is organized. \n",
    "- All we need to know are the dimension name and the label we wish to index i.e. `data.sel(lat=47.5)` works regardless of whether `lat` is the first or second dimension of the array and regardless of whether `47.5` is the first or second element of `lat`. \n",
    "- We have already told Xarray that `lat` is the second dimension when we created data: Xarray keeps track of this so we don’t have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing with Selection\n",
    "\n",
    "- Use the `slice` function alon a dimension to determine the range of coordinates we want to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(time=slice('2010-01-02', '2010-01-03'), \n",
    "            lon=slice(-100, -70), \n",
    "            lat=slice(35, 55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `loc` (array-like slicing) to obtain the same information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.loc['2010-01-02':'2010-01-03', 35:55, -100:-70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computations\n",
    "\n",
    "- When we perform mathematical manipulations of xarray DataArrays, the coordinates are also included.\n",
    "- DataArrays work similarly to Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can scale and offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Numpy built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.25*xr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `where()` to conditionally switch between values:\n",
    "\n",
    "```python\n",
    "  xr.where(cond, x, y)\n",
    "```\n",
    "\n",
    "- When `cond` is True, return values from `x`, otherwise returns values from `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.where(xr_data > 287.5, np.nan, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.where(xr_data > 287.5, np.nan, 1).isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sum all the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std(dim=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std(dim=(\"lat\", \"lon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation operations can use dimension names instead of axis numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do similar calculations in `Numpy`. We need to specify the index of the axis of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.mean(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arithmetic operations broadcast are based on dimension name. \n",
    "- You don not need to insert dummy dimensions for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xr.DataArray(np.random.random(nlats), [xr_data.coords[\"lat\"]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = xr.DataArray(np.random.random(6), dims=\"lev\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![a+b](broadcast.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not need to worry about the order of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data - xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations also align based on index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data[:-1] - xr_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation\n",
    "- `Xarray` does interpolation on the fly.\n",
    "- By default, the linear interpolation is used.\n",
    "- The available interpolation methods are:\n",
    "    - {`linear`, `nearest`} for multidimensional array.\n",
    "    - {`linear`, `nearest`, `zero`, `slinear`, `quadratic`, `cubic`} for 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40, lon=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(time=\"2010-01-02 18:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "\n",
    "Time series plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=[\"lat\", \"lon\"]).plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(time=\"2010-01-02 18:00:00\", lon=-102).plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=('time', 'lon')).plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = xr_data.values.min()\n",
    "vmax = xr_data.values.max()\n",
    "xr_data.sel(time=\"2010-01-02 12:00:00\").plot(vmin=vmin, vmax=vmax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(lon=-108.0).transpose().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Going to Pandas**\n",
    "\n",
    "Xarray objects can be easily converted to and from Pandas objects using the `to_series()`, `to_dataframe()` and `to_xarray()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series = xr_data.to_series()\n",
    "pd_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Xarray Datasets</font>\n",
    "\n",
    "- `xarray.Dataset` is a dict-like container of aligned DataArray objects. \n",
    "- It can be seen as a multi-dimensional generalization of the `pandas.DataFrame`.\n",
    "- Variables in datasets can have different `dtype` and even different dimensions.\n",
    "- **All dimensions are assumed to refer to points in the same shared coordinate system**:\n",
    "     - If two variables have dimension `x`, that dimension must be identical in both variables.\n",
    "     \n",
    "Here is an example of how we might structure a dataset for a weather forecast:\n",
    "\n",
    "![fig_dataset](https://docs.xarray.dev/en/stable/_images/dataset-diagram.png)\n",
    "\n",
    "Image Source: docs.xarray.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a dataset with three `DataArrays` named `da_1`, `da_2` and `da_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst = xr.Dataset({\"da_1\": xr_data, \n",
    "                     \"da_2\": (\"lat\", [7.5, 2.6, -6.4, 15.7, 3.7]), \n",
    "                     \"da_3\": np.pi})\n",
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the dictionary or dot indexing to pull out `Dataset` variables as `DataArray` objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst[\"da_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray automatically aligns `da_2` with `DataArray` `da_1`: they share the same coordinate system so that:\n",
    "\n",
    "`xr_dst.da_1['lat'] == xr_dst.da_2['lat'] == xr_dst['lat']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_1.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Dataset to a netCDF file\n",
    "- We can save the dataset in a netCDF file by using the `to_netcdf` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_filename = \"sample_netcdf.nc\"\n",
    "xr_dst.to_netcdf(nc_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read back the netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(nc_filename) as fid:\n",
    "     print(fid.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Using `Pandas DataFrames`</font> \n",
    "\n",
    "- We use web scrapping to access the <a href=\"https://neo.gsfc.nasa.gov/\">NASA Earth Observations (NEO)</a> website to obtain the AOT measurements for a given range of days (from 2000 to present).\n",
    "- For each daily reading, we create a `Pandas DataFrame` that is use to create a `Xarray DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as reqs\n",
    "import io\n",
    "from bs4 import BeautifulSoup as bso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the day range of interest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = '2019-01-01'\n",
    "end_date = '2019-12-31'\n",
    "data_freq = 'D' # daily ('D'), monthly 'M'\n",
    "\n",
    "datasetID = 'MODAL2_M_AER_OD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(beg_date, end_date, freq='D'):\n",
    "    \"\"\"\n",
    "      Create a list containing all the dates between\n",
    "      beg_date and end_date.\n",
    "      \n",
    "      Input parameters:\n",
    "         - beg_date: (str) start date in the format YYYY-MM-DD\n",
    "         - end_date: (str) end   date in the format YYYY-MM-DD\n",
    "         - freq: (str) frequency - 'D' for days and 'M' for months\n",
    "      Returned value:\n",
    "         - a list of dates in the format YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    pd_series = pd.date_range(start=beg_date, end=end_date, freq=freq)\n",
    "    list_dates = [dt.strftime('%Y-%m-%d') for dt in pd_series]\n",
    "    return list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls(datasetID, list_dates, freq='D'):\n",
    "    \"\"\"\n",
    "      Create a list containing the urls for the websites we\n",
    "      want to access to grab the full addresses of the CVS files\n",
    "      (that have the mesurements).\n",
    "      \n",
    "      Input parameters:\n",
    "         - datasetID: (str) dataset identifier for the data of interest\n",
    "         - list_dates: (list) list of dates of interest\n",
    "      Returned value:\n",
    "         - a list of urls\n",
    "    \"\"\"\n",
    "    freq_tag = '&date='\n",
    "    if freq == 'M':\n",
    "        freq_tag = '&year='\n",
    "    elif freq == 'Y':\n",
    "        freq_tag = '&year='\n",
    "    url = 'https://neo.gsfc.nasa.gov/view.php?datasetId='\n",
    "    url_base = url+datasetID+'&date='\n",
    "    list_urls = [url_base+dt for dt in list_dates]\n",
    "    return list_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_dates(beg_date, end_date, freq=data_freq)\n",
    "urls = generate_urls(datasetID, dates)\n",
    "\n",
    "assert len(urls) == len(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse each website to obtain the location of the CSV files (conatining measurements):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_urls = list()\n",
    "for url in urls:\n",
    "    source = reqs.get(url)\n",
    "    mysoup = bso(source.text, 'html.parser')\n",
    "    href_tags = mysoup.find_all(href=True)\n",
    "    for tag in href_tags:\n",
    "        loc_url = tag[\"href\"]\n",
    "        if \"CSV\" in loc_url:\n",
    "            csv_urls.append(loc_url)\n",
    "            break\n",
    "\n",
    "print(len(csv_urls), len(urls), len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read all the CSV files and create a Xarray DataSet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = list()\n",
    "dts = list()\n",
    "for i, csv_file in enumerate(csv_urls):\n",
    "    print(i, csv_file)\n",
    "    dts.append(pd.to_datetime(dates[i]))\n",
    "    \n",
    "    resp = reqs.get(csv_file)\n",
    "    df = pd.read_csv(io.StringIO(resp.text), \n",
    "                     index_col=0, na_values=99999.0)\n",
    "    da = xr.DataArray(df.values, \n",
    "                      coords=[[float(lat) for lat in df.index], \n",
    "                              [float(lon) for lon in df.columns]],\n",
    "                      dims=['latitude', 'longitude'])\n",
    "    \n",
    "    das.append(da)\n",
    "\n",
    "xr_dst = xr.concat(das, pd.Index(dts, name='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "\n",
    "First thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays = xr_dst[0:31]\n",
    "thirtydays.plot(x=\"longitude\", y=\"latitude\",\n",
    "                col=\"date\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average over the first thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom over the USA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = thirtydays.sel(latitude=slice(50.05, 20.05),\n",
    "                 longitude=slice(-125.05, -66.50))\n",
    "usa.mean(dim='date').plot(cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax_p = plt.gca(projection=ccrs.LambertConformal(), aspect='auto')\n",
    "ax_p.coastlines()\n",
    "ax_p.set_extent([-125.05, -66.50, 20.05, 50.05])\n",
    "usa.mean(dim='date').plot.imshow(ax=ax_p, cmap='RdBu_r', \n",
    "                                 transform=ccrs.PlateCarree());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_means = xr_dst.groupby(xr_dst.date.dt.month).mean(dim='date')\n",
    "monthly_means.plot(x='longitude', y='latitude', col='month', \n",
    "                   cmap='RdBu_r', col_wrap=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Exercise</font>\n",
    "\n",
    "The website \n",
    "\n",
    "[https://neo.gsfc.nasa.gov/](https://neo.gsfc.nasa.gov/)\n",
    "\n",
    "also contains measurements for:\n",
    "\n",
    "- Carbon Monoxide (`MOP_CO_M`)\n",
    "- Cloud optical Thickness (`MODAL2_M_CLD_OT`)\n",
    "- Cloud Fraction (`MODAL2_M_CLD_FR`)\n",
    "- Land Surface Temperature (`MOD_LSTD_CLIM_M`)\n",
    "- etc.\n",
    "\n",
    "Select one of them and retrieve dataset for a a given time period. You may want to first verify the raange of dates where the measurements are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Manipulating a netCDF File</font> \n",
    "\n",
    "- We will manipulate [NOAA NCEP Reanalysis](https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/ncep.reanalysis/surface/catalog.html) surface data.\n",
    "- The reanalysis project uses an analysis/forecast system to perform data assimilation using past data from 1948 to the present.\n",
    "- Spatial coverage: 2.5 degree latitude x 2.5 degree longitude global grid (144x73).\n",
    "- It produces outputs 4 times per day.\n",
    "- Here, we will focus on surface air temperature for 2018: 4x365 = 1460 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xr.set_options(file_cache_maxsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995.2018.nc\"\n",
    "ds = xr.open_dataset(url, engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content of the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataArrays in the Dataset: \\n\\t {list(ds.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Variables in the Dataset: \\n\\t {list(ds.variables.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensions in the Dataset: \\n\\t {list(ds.dims.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coordinates in the Dataset: \\n\\t {list(ds.coords.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the global attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute = ds.attrs\n",
    "dts_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dts_attribute['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute['References']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Work With the NetCDF Data Structure </font>\n",
    "\n",
    "- An Xarray contains metadata making it self-describing. \n",
    "- There are three dimensions to consider when working with this data which represent the `x`, `y` and `z` dimensions of the data:  \n",
    "     - latitude/longitude/time.\n",
    "- This particular dataset contains global time series of surface air temperatures for 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Air Temperature dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D = ds.air\n",
    "air_temp2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get latitude/longitude information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum/Maximum latidtude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min/Max latitudes: \\n\\t {air_temp2D['lat'].values.min()} {air_temp2D['lat'].values.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min/Max longitudes: \\n\\t {air_temp2D['lon'].values.min()} {air_temp2D['lon'].values.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the time information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D[\"time\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Earliest date: {air_temp2D['time'].values.min()}\")\n",
    "print(f\"Latest   date: {air_temp2D['time'].values.max()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(air_temp2D[\"time\"].values))\n",
    "print(air_temp2D[\"time\"].values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self describing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = air_temp2D.attrs\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slicing the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single `x`, `y` combination from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 50\n",
    "longitude = air_temp2D[\"lon\"].values[key]\n",
    "latitude = air_temp2D[\"lat\"].values[key]\n",
    "\n",
    "print(f\"Longitude = {longitude} \\n Latitude = {latitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the selected location on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "ax = plt.axes(projection=map_projection)\n",
    "ax.stock_img()\n",
    "\n",
    "# Plot the selected location \n",
    "plt.plot([longitude], [latitude], 'r*', \n",
    "        transform=data_transform,\n",
    "        color=\"purple\", \n",
    "         markersize=10)\n",
    "\n",
    "ax.set(title=f\"Location of the {latitude} Lat and {longitude} Lon Being Used to Slice Your netcdf Climate Data File\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time series data at the selected location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point = air_temp2D.sel(lat=latitude, lon=longitude)\n",
    "one_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you slice the data by a single point, the output data only has a single array of values. \n",
    "- The values represent air temperature (in K) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the first few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series plot at a single location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make the plot a bit prettier by using Matplotlib plot parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "one_point.plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                    markerfacecolor=\"purple\",\n",
    "                    markeredgecolor=\"purple\");\n",
    "ax.set(title=\"Time Series For a Single Lat/Lon Location\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice the Data By Time and Location</font>\n",
    "- We want to slice the data at a selected lat/lon location and for the months of April to June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = \"2018-04-01\"\n",
    "end_date = \"2018-06-30\"\n",
    "temp_apr_jun = air_temp2D.sel(time=slice(beg_date, end_date),\n",
    "                              lat=latitude, lon=longitude)\n",
    "temp_apr_jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_apr_jun.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "temp_apr_jun.plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\")\n",
    "ax.set(title=\"April-June Time Series of Temperature Data For A Single Location\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Time series at specific latitudes and along a longitude line</font>\n",
    "\n",
    "- We can use line plots to check the variation of air temperature at three different latitudes along a longitude line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "air_temp2D.isel(lon=10, lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice The Data Across a Spatial Extent For A Specific Time Period</font>\n",
    "\n",
    "- We use `.sel()` combined with `slice()` to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = \"2018-04-01\"\n",
    "end_date = \"2018-04-01\"\n",
    "one_day_data = air_temp2D.sel(time=slice(beg_date, end_date))\n",
    "one_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `.plot()` on the data, the default plot is a histogram representing the range of raster pixel values in your data for all time periods (3 months in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Spatial Plots</font>\n",
    "- If you want to plot the data spatially as a raster, you can use `.plot()` but specify the lon and lat values as the x and y dimensions to plot. \n",
    "- You can add the following parameters to your .plot() call to make sure each time step in your data plots spatially:\n",
    "    - `col_wrap=`: adjust how how many columns the each subplot is spread across \n",
    "    - `col=`: what dimension is being plotted in each subplot.\n",
    "\n",
    "Here, we want a single raster for each time record in the data so you specify `col='time'`. `col_wrap=2` forces the plots to be on two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot at a specific date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time = one_day_data.time.values[-1]\n",
    "one_day_data.sel(time=last_time).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for all the dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=2)\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the Cartopy map projection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "aspect = one_day_data.shape[2] / one_day_data.shape[1]\n",
    "\n",
    "p = one_day_data.plot(transform=data_transform,  # the data's projection\n",
    "                      col='time', col_wrap=2,\n",
    "                      aspect=aspect,\n",
    "                      figsize=(10, 10),\n",
    "                      subplot_kws={'projection': map_projection})  # the plot's projection\n",
    "\n",
    "for ax in p.axes.flat:\n",
    "    ax.coastlines()\n",
    "    #ax.set_extent(extent)\n",
    "\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Cartopy only to do the countour plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    one_day_data[i].plot()\n",
    "    ax.coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.util\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "#fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "#ax = axes.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    data = one_day_data[i].values\n",
    "    lats = one_day_data[i]['lat'].values\n",
    "    lons = one_day_data[i]['lon'].values\n",
    "\n",
    "    data, lons = cartopy.util.add_cyclic_point(data, coord=lons)\n",
    "    cp = plt.contourf(lons, lats, data, 60,\n",
    "                      cmap='jet', transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    title = f'Time = {str(one_day_data[i].time.values)[0:19]}'\n",
    "    ax.set_title(title)\n",
    "\n",
    "# add a subplot for vertical colorbar\n",
    "bottom, top = 0.1, 0.9\n",
    "left, right = 0.1, 0.8\n",
    "fig.subplots_adjust(top=top, bottom=bottom, \n",
    "                    left=left, right=right, hspace=0.15, wspace=0.25)\n",
    "cbar_ax = fig.add_axes([0.85, bottom, 0.05, top-bottom])\n",
    "fig.colorbar(cp, cax=cbar_ax);  # plot colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Perform Correlation Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the dataset by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp  = air_temp2D.groupby('time.month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the monthly climatologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim = grp_air_temp.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the anomaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom = grp_air_temp - air_temp_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the anomaly for the first time record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom[0].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot anomaly time series at a specific location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_ref = air_temp_anom.sel(lon=200, lat=0, method='nearest')\n",
    "air_temp_ref.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def corrrelation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_cor = corrrelation(air_temp_anom, air_temp_ref, dims='time')\n",
    "pc = air_temp_cor.plot()\n",
    "pc.axes.set_title('Correlation btw. global airTemp Anomaly and airTemp Anomaly at one point');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the time series spatial means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg = air_temp_anom.mean(dim=['lat', 'lon'])\n",
    "air_temp_anom_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation using datetime strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_data = air_temp2D.interp(time=[\"2018-03-15\", \"2018-03-16\"])\n",
    "inter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_data.plot(x=\"lon\", y=\"lat\", col=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Manipulating 3D Field </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3D=\"https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/air.2020.nc\"\n",
    "xds = xr.open_dataset(url_3D)\n",
    "xds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the dimension values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.level.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lat.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the 3D temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D = xds.air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plots at `600 mb`, `25.0` degree longitude and at three latitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=25.0).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if I what to do the same plot at longitude `24.5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=24.5).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform an interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600.).isel(lat=[19, 21, 22]).interp(lon=24.5).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600.).interp(lon=24.5, lat=21.0).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D = air_temp3D.groupby('time.month').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D.sel(level='1000.0').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"month\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean: Contour plot at each vertical level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.mean(dim='time').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"level\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Zonal Mean Height plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "air_temp3D.mean(dim='time').mean(dim='lon').plot(ax=ax, \n",
    "                                                 x='lat', \n",
    "                                                 y='level')\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Vertical Level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Exercise</font>\n",
    "\n",
    "Modify the code shown in:\n",
    "\n",
    "[https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6](https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6)\n",
    "\n",
    "to reproduce the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<p>\n",
    "\n",
    "<details><summary><b><font color='green'>Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "URL ='https://esgf.nccs.nasa.gov/thredds/dodsC/CMIP6.CMIP.NASA-GISS.GISS-E2-1-G.historical.r1i1p1f1.Amon.tas.gn.tas.20180827.aggregation.1'\n",
    "nc = xr.open_dataset(URL, engine='netcdf4')\n",
    "\n",
    "# do the average of the each month over 164 years\n",
    "da = nc['tas']\n",
    "slice_da = da.sel(lat=slice(18.92, np.max(da.lat.values)),\n",
    "                  lon=slice(188.30, np.max(da.lon.values)))\n",
    "\n",
    "monthly_data = slice_da.groupby('time.month').mean('time')\n",
    "monthly_data.plot(x=\"lon\",\n",
    "                y=\"lat\",\n",
    "                col=\"month\",\n",
    "                col_wrap=3,\n",
    "                cmap='jet')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Application: Subsetting a Dataset and Writing in File</font>\n",
    "\n",
    "- We read a multi-year GEOS-5 dataset that contains 16 fields (`u`, `v`, `epv`, `delp`, `t`, etc.)\n",
    "- We select the variable `t` (3D air temperature) with a latitude from 80N to 82N, a longitude from 72W to 70W, and a time from April 28, 2021 to May 5, 2021.\n",
    "- We perform analyses.\n",
    "- We write out the slice in a netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL ='https://opendap.nccs.nasa.gov/dods/GEOS-5/fp/0.25_deg/assim/tavg3_3d_asm_Nv'\n",
    "geos5_xrs = xr.open_dataset(URL, engine='netcdf4')\n",
    "geos5_xrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the time range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting Time: \\n\\t {geos5_xrs.time.values[0]}\")\n",
    "print(f\"Ending Time:   \\n\\t {geos5_xrs.time.values[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the time resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time resolution: {geos5_xrs.time.attrs['resolution']} day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a slice of the air temperature field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds = geos5_xrs.t.sel(lat=slice(80, 82), \n",
    "                       lon=slice(-72,-70), \n",
    "                       time=slice(\"2021-04-28T01:30:00\", \n",
    "                                  \"2021-05-05T22:30:00\"))\n",
    "t_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series of mean surface temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\", label=\"Local Domain\")\n",
    "geos5_xrs.t.sel(lev=72,\n",
    "                time=slice(\"2021-04-28T01:30:00\", \n",
    "                           \"2021-05-05T22:30:00\")).mean(dim=[\"lat\", 'lon']).plot.line(color=\"green\", label=\"Entire Domain\")\n",
    "\n",
    "plt.legend(ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time average surface temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the axes direction:\n",
    "- The keyword arguments `xincrease` and `yincrease` let you control the axes direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax, \n",
    "                                                    xincrease=False, \n",
    "                                                    yincrease=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contour Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contour(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contourf(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine two plots into subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax[0], \n",
    "                                                    marker=\"o\", \n",
    "                                                    color=\"grey\",\n",
    "                                                    markerfacecolor=\"purple\",\n",
    "                                                    markeredgecolor=\"purple\");\n",
    "\n",
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contourf(x=\"lon\", y=\"lat\", ax=ax[1]);\n",
    "#t_ds.sel(lev=72).mean(dim=\"time\").plot(x=\"lon\", y=\"lat\", ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the slice in a netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.to_netcdf(\"air_temperature_subset.nc\", engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reading Multiple netCDF Files</font>\n",
    "\n",
    "- The function `open_mfdataset` opens multiple files as a single dataset.\n",
    "- Requires `Dask` to be installed.\n",
    "- The attributes from the first dataset file are used for the combined dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Multiple NCEP Reanalysis Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/surface'\n",
    "byear = 2017\n",
    "eyear = 2019\n",
    "list_files = ['{0}/air.sig995.{1:04d}.nc'.format(url, years) \n",
    "              for years in range(byear,eyear,1)]\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(list_files)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_airT = ds.air\n",
    "dst_airT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_airT.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select data for a given time range:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2017 = dst_airT.sel(time=slice(\"2017-01-01\", \"2017-12-31\"))\n",
    "air_temp2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2017.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the daily means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dst = dst_airT.resample(time='1D').mean()\n",
    "daily_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plot at Greenbelt, MD location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_ref =  39.00\n",
    "lon_ref = -76.88\n",
    "daily_dst_ref = daily_dst.sel(lon=lon_ref, lat=lat_ref, method='nearest')\n",
    "daily_dst_ref.to_pandas().T.plot()\n",
    "units = dst_airT.attrs['units']\n",
    "plt.ylabel(f\"Air Temperature ({units})\")\n",
    "plt.title('Time series plot for Greenbelt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the monthly means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dst = dst_airT.resample(time='1M').mean()\n",
    "monthly_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dst.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the annual means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst = dst_airT.resample(time='1A').mean()\n",
    "yearly_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst.plot(x=\"lon\", y=\"lat\",\n",
    "                col=\"time\", col_wrap=2)\n",
    "plt.suptitle(\"Yearly Means\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute seasonal values:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `JFM`, `AMJ`, `JAS` and `OND`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst = dst_airT.resample(time='QS-JAN').mean()\n",
    "JFM_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (JFM, AMJ, JAS, OND)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `DJF`, `MAM`, `JJA` and `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst = dst_airT.resample(time='QS-DEC').mean()\n",
    "DJF_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use the following for the seasons `DJF`, `MAM`, `JJA`, `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst2 = dst_airT.groupby('time.season').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (DJF, MAM, JJA, SON)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Accessing HDF5 Files</font>\n",
    "\n",
    "We can only access data within groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the hdf5-file using netCDF4 in diskless non-persistence mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/master/xarray/sample_hdf5.h5\"\n",
    "hdf5_fname = \"sample_hdf5.h5\"\n",
    "urllib.request.urlretrieve(url, hdf5_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = nc4.Dataset(hdf5_fname, diskless=True, persist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the file contents including `groups`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ncf.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make use of `xarray.backends.NetCDF4DataStore` to open the wanted hdf5-groups (Xarray can only get hold of one hdf5-group at a time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_group_name = '3D_Data'\n",
    "nch = ncf.groups.get(hdf5_group_name)\n",
    "xds = xr.open_dataset(xr.backends.NetCDF4DataStore(nch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give you a dataset `xds` with all attributes and variables (datasets) of the group hdf5-name. \n",
    "- Note that you will not get access to sub-groups. \n",
    "- You would need to claim subgroups by the same mechanism. \n",
    "- If you want to apply Dask, you would need to add the keyword chunking with wanted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = xds.temp\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.isel(phony_dim_3=1, phony_dim_4=2).plot(x=\"phony_dim_6\", \n",
    "                                             y=\"phony_dim_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding data\n",
    "\n",
    "- There is no (real) automatism for decoding data like this could be done for NetCDF files. \n",
    "- If you have a integer compressed 2d variable (dataset) `var` with some attributes `gain` and `offset` you can add the NetCDF specific attributes `scale_factor` and `add_offset` to the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = ''\n",
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will decode your variable using netcdf mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You could try to give the extracted dimension useful names (you will get something like phony_dim_0, phony_dim_1, ..., phony_dim_N) and assign new (as in example) or existing variables/coordinates to those dimensions to gain as much of the xarray machinery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "dims = var.dims\n",
    "xds[var_name] = var.rename({dims[0]: 'x', dims[1]: 'y'})\n",
    "xds = xds.assign({'x': (['x'], xvals, xattrs)})\n",
    "xds = xds.assign({'y': (['y'], yvals, yattrs)})\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
