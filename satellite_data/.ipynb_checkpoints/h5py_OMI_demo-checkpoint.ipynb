{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://github.com/astg606/py_materials/blob/master/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1> <font color=\"red\">Reading OMI hdf5 Files using h5py</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook shows an example of how to use the **h5py**, **Numpy**, **Xarray**, **Matplotlib**, **Cartopy**, and **hvplot** Python packages to work with a OMI file in HDF5 format.  \n",
    "\n",
    "The main workflow steps are:\n",
    "- Open a OMI HDF5 file\n",
    "- Identify the groups, subgroups and datasets\n",
    "- Read the global file metadata\n",
    "    - Recognize the file attribute\n",
    "    - Find names of variables and their attributes\n",
    "- Read dataset from file\n",
    "- Visualize satellite data on a map\n",
    "- Read a collection of data files and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Primary References/Resources</font>\n",
    "\n",
    "- [Ozone Monitoring Instrument (OMI)](https://aura.gsfc.nasa.gov/omi.html)\n",
    "- [h5py Quick Start Guide](https://docs.h5py.org/en/stable/quick.html)\n",
    "- [OMNO2d File Specification](https://docserver.gesdisc.eosdis.nasa.gov/repository/Mission/OMI/3.3_ScienceDataProductDocumentation/3.3.2_ProductRequirements_Designs/OMNO2d_FileSpec_V003.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Import the Python Packages</font>\n",
    "\n",
    "Six Python packages (libraries)  used in this Notebook:\n",
    "- **h5py**: Read HDF5 files\n",
    "- **NumPy**: Perform array operations\n",
    "- **Xarray**: Work with labeled multi-dimensional arrays\n",
    "- **Matplotlib**: Make static plots (mainly two-dimensional)\n",
    "- **Cartopy**: Create maps\n",
    "- **hvplot**: Create interactive plots/maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "from cartopy import crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles off alphabetical sorting\n",
    "pprint.sorted = lambda x, key=None:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">[What is OMI?](https://www.earthdata.nasa.gov/learn/find-data/near-real-time/omi) </font>\n",
    "\n",
    "- The Ozone Monitoring Instrument (OMI) aboard NASA's Aura satellite (launched in 2004) measures ozone from Earth's surface to top-of-atmosphere. \n",
    "  - OMI is a nadir-viewing wide-field-imaging spectrometer, giving daily global coverage.\n",
    "  - OMI measures the key air quality components such as nitrogen dioxide (NO$_2$), sulfur dioxide (SO$_2$), bromine oxide (BrO), OClO, and aerosol characteristics.\n",
    "  - OMI provides mapping of pollution products from an urban to super-regional scale.\n",
    "- Near real-time (NRT) OMI data are available through LANCE generally within three hours after a satellite observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Accessing a Sample HDF5 Data File</font>\n",
    "\n",
    "We consider:\n",
    "\n",
    "- [OMI/Aura Ozone (O3) Total Column Daily L3 Global 0.25deg Lat/Lon Grid](https://acdisc.gesdisc.eosdis.nasa.gov/data/Aura_OMI_Level3/OMTO3e.003/2022/OMI-Aura_L3-OMTO3e_2022m0709_v003-2022m0711t031807.he5.xml)\n",
    "- This is the Level-3 Aura/OMI Global TOMS-Like Total Column Ozone gridded product [OMTO3e](https://disc.gsfc.nasa.gov/datasets/OMTO3e_003/summary).\n",
    "- Time Coverage: `2022-07-09 00:00:00` to `2022-07-09 23:59:59`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 1: Identify the Location of the File</font>\n",
    "\n",
    "Directory where the OMI files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = \"/Users/jkouatch/myTasks/PythonTraining/ASTG606/Materials/sat_data/OMI_Data/\"\n",
    "data_dir = \"/tljh-data/sat_data/OMI_Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full path to the file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_dir, \"OMI-Aura_L3-OMTO3e_2022m0709_v003-2022m0711t031807.he5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 2: Open the File</font>\n",
    "\n",
    "Opening file for reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = h5py.File(file_name, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 3: Identify the Possible Groups, Subgroups and Datasets</font>\n",
    "\n",
    "An HDF5 file is a container for two kinds of objects: \n",
    "   1. **Datasets**: Array-like collections of data.\n",
    "   2. **Groups**: Folder-like containers that hold datasets and other groups.\n",
    "* Each group or dataset can have an associated attribute list to provide extra information related to the object.\n",
    "   \n",
    "![hdf5](https://miro.medium.com/max/1400/0*_vh8GIkBQNOg42uv.jpg)\n",
    "Image Source: [https://www.neonscience.org/about-hdf5](https://www.neonscience.org/about-hdf5)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the top level groups using the `keys()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_keys = list(fid.keys())\n",
    "print(fid_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List each top level group and the number of its members:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_values = list(fid.values())\n",
    "print(fid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_items = dict(fid.items())\n",
    "print(fid_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visit()` function returns the hierarchy of the file by utilizing the Python `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even incorporate `lambda` or use predefined functions to retrieve more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(lambda x: print(x, fid[x], \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve hierarchy and corresponding objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_more(name):\n",
    "    print(name, fid[name], \"\\n\")\n",
    "    \n",
    "fid.visit(print_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the type of each object, for groups, the number of members and its path is returned. For datasets, the name, shape, and array type is returned instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the datasets and their attributes: Use `visititems`\n",
    "\n",
    "In addition to **file-level attributes** and even **coordinate metadata**, we can access our **dataset attributes** as they, too, use the `attrs` variable to access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(name, obj):\n",
    "    print(f\"{name}: \\n\\t {dict(obj.attrs)}\")\n",
    "\n",
    "fid.visititems(print_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List each item and determine if it is a group or a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_2(name, obj):\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        print(f\"{name:>25}: --> Group\")\n",
    "    elif isinstance(obj, h5py.Dataset):\n",
    "        print(f\"{name:>25}: --> Dataset\")\n",
    "    else:\n",
    "        print(f\"{name:25}: --> unknown type\")\n",
    "\n",
    "\n",
    "fid.visititems(print_all_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 4: Moving Around</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get to a particular subgroup in the file, we use a dictionary-like syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fid['HDFEOS']['ADDITIONAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(fid['HDFEOS']['ADDITIONAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group = fid['HDFEOS']['GRIDS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access group names (includes path),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parent group of a subgroup, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the file to which the group belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can access the **attributes** through the `attrs` variable which follows a dictionary-like interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs = dict(sample_group.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this group doesn't have any attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 5: Accessing Top-level Metadata</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File-level Attributes\n",
    "\n",
    "From displaying all attributes above, we can see that file-level attributes are stored as attributes w/in the `HDFEOS/ADDITIONAL/FILE_ATTRIBUTES/` sub-group.\n",
    "\n",
    "Since attributes have a dictionary-like interface in `h5py`, it's simple to obtain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "\n",
    "file_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5py` stores the attribute values as `NumPy` data types: `numpy.ndarray` for all numeric and array representations and `numpy.bytes_` for all string and character representations along with tuples and dictionaries.\n",
    "\n",
    "While we could leave them that way, it would definitely be more convenient to convert them into more familiar data types due to their string representations. Thankfully, the `isinstance()` function exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in file_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    file_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(file_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinates and Plotting Information\n",
    "\n",
    "Our plotting-related metadata seems to be stored as attributes in the `HDFEOS/GRIDS/OMI Column Amount O3` sub-group. We can try to access them the same way as file attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs = dict( fid['HDFEOS']['GRIDS']['OMI Column Amount O3'].attrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data type conversion method, we can get more convenient data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in plot_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    plot_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attributes give us all the information we need to construct coordinates need for `XArray` datasets.\n",
    "\n",
    "First, we want to identify our coordinate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonW = plot_attrs['GridSpan'][0]\n",
    "lonE = plot_attrs['GridSpan'][1]\n",
    "latS = plot_attrs['GridSpan'][2]\n",
    "latN = plot_attrs['GridSpan'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to obtain the number of lats and lons in the grid (our dimension sizes), which is also readily available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "lat_size = plot_attrs['NumberOfLatitudesInGrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using NumPy's `linspace()` function, we can now create our coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.linspace(lonW, lonE, lon_size)\n",
    "lats = np.linspace(latS, latN, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Longitudes:\\n', lons)\n",
    "print('Latitudes:\\n', lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 6: Accessing Data Fields and Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking back at the file layout, we can see that the data appears to be w/in the subgroup `/HDFEOS/GRIDS/OMI Column Amount O3/Data Fields/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = fid['HDFEOS']['GRIDS']['OMI Column Amount O3']['Data Fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of the `visit()` function once again and get some descriptive information and attributes of each dataset w/in the sub-group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(name):\n",
    "    print('Name:', name, \n",
    "          '\\n\\tInfo:', data_group[name],\n",
    "          '\\n\\tAttrs:', data_group[name].attrs.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.visit(print_data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "Given our previous knowledge of reading attributes, accessing important keys such as missing and fill values, scale factors, and offset values will be straightforward.\n",
    "\n",
    "Let's use the `SolarZenithAngle` dataset as our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = data_group['SolarZenithAngle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now examine the attributes more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs = dict(sample_ds.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for our signature data type conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in sample_ds_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    sample_ds_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract our targeted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sample_ds_attrs.items():\n",
    "    if key == '_FillValue':\n",
    "        fill = value  \n",
    "    if key == 'ScaleFactor':\n",
    "        scale = value\n",
    "    if key == 'Offset':\n",
    "        offset = value\n",
    "# data = data * scale + offset\n",
    "    \n",
    "print('Fill Value:', fill)\n",
    "print('Scale Factor:', scale)\n",
    "print('Offset:', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need ot do is to access our actual **data**. `h5py` makes this really simple. All we need to do is add `[()]` next to our dataset object and all of it is now in `NumPy` array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Accessing Dimensions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to access in our HDF5 file is dataset **dimensions**, known as **dimension scales** in `h5py`.\n",
    "\n",
    "We can access a dataset's dimensions by getting a list of dimension objects using the `dims()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims = list(sample_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension objects are simply another `HDF5` dataset. Normally, one would be able to access dimension labels and scales associated with each axis. For our OMI satellite data file, our dimension objects are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_ds_dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims[0].label   # would return dimension label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sample_ds_dims[0].items())   # would return label and scales associated with this axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_ds_dims[0][0]   # would return scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can try to match the dataset shape to our plotting attributes describing lon and lat size to assign our `xarray` dimension names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lon_size, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_ds.shape[0] == lon_size:\n",
    "    sample_ds_dims = ['lon', 'lat']\n",
    "elif sample_ds.shape[0] == lat_size:\n",
    "    sample_ds_dims = ['lat', 'lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Configuring the order is important for our `xarray` DataArray initilizations.\n",
    "\n",
    "Now that we've gotten all the information we need, we can close our file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Conversion to Xarray DataArrays and Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've been able to get all of the necessary information to create an `xarray` dataset, we can start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(filename):\n",
    "    '''\n",
    "    Receive an hdf5 file name, open it and \n",
    "    return the file identifier object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        file name\n",
    "    Returns\n",
    "    -------\n",
    "    fid\n",
    "        h5py file identifier object\n",
    "    '''\n",
    "    fid = h5py.File(filename, 'r')\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_group(fid):\n",
    "    '''\n",
    "    Use the file identifier to extract a datafield subgroup.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fid\n",
    "         h5py file identifier object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_group : dict\n",
    "          the data field group (contents) of the file\n",
    "    '''\n",
    "    # contents of our parent group\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS']) \n",
    "    # our subparent group object\n",
    "    subparent = list(parent_contents.values())[0]\n",
    "    # contents of our subparent group\n",
    "    subparent_contents = dict(subparent)   \n",
    "    # our data group object\n",
    "    data_group = list(subparent_contents.values())[0]   \n",
    "    \n",
    "    return dict(data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_dtype(sample_dict):\n",
    "    '''\n",
    "    Converts attribute dictionary from Numpy data types \n",
    "    to general Python data types\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_dict : dict\n",
    "         A dictionary of attributes\n",
    "         \n",
    "    Returns\n",
    "    sample_dict : dictt\n",
    "         A dictionary of attributes\n",
    "    '''\n",
    "    for key, item in sample_dict.items():\n",
    "        if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "            item = list(item)\n",
    "        \n",
    "            if len(item) == 1:\n",
    "                item = item[0]\n",
    "        elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "            item = str(item.astype('str'))\n",
    "        \n",
    "            if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "                item = eval(item)\n",
    "            # **eval() relaiability??**\n",
    "            \n",
    "        sample_dict[key] = item   # Updates any changes to the key value\n",
    "        \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid_attrs(fid):\n",
    "    \"\"\"\n",
    "    Use the file identified to return the file-level attributes \n",
    "    in the proper data type\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    fid\n",
    "        file identifier\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fid_attrs : dict\n",
    "         A dictionary of attributes.\n",
    "    \"\"\"\n",
    "    fid_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "    fid_attrs = convert_dict_dtype(fid_attrs)\n",
    "    \n",
    "    fid_attrs.update(get_plot_attrs(fid))\n",
    "    \n",
    "    return fid_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_attrs(fid):\n",
    "    \"\"\"\n",
    "    Use a file attribute returns the plotting attributes.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    fid\n",
    "        h5py file identifier\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    plot_attrs : dict\n",
    "        a dictionatory\n",
    "    \"\"\"\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS'])\n",
    "    subgroup = list(parent_contents.values())[0]\n",
    "    \n",
    "    plot_attrs = dict(subgroup.attrs)\n",
    "    plot_attrs = convert_dict_dtype(plot_attrs)\n",
    "    \n",
    "    return plot_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attrs(ds):\n",
    "    \"\"\"\n",
    "       Give a dataset identifier, return the dataset attribute.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - ds: dataset identifier\n",
    "       Returned value:\n",
    "          - ds_attrs: a dictionary\n",
    "    \"\"\"\n",
    "    ds_attrs = dict(ds.attrs)\n",
    "    ds_attrs = convert_dict_dtype(ds_attrs)\n",
    "    \n",
    "    return ds_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attribute_value(ds_attrs, attr_name):\n",
    "    '''\n",
    "    Obtain the value of a specified attribute in a dataset.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    ds_attrs : dict\n",
    "         A dictionary of dataset attributes\n",
    "    attr_name : str\n",
    "         Attribute name    \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    value: float, int, str, list\n",
    "         Value of the attribute. If attribute not available, None.\n",
    "    '''\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == attr_name:\n",
    "            return value \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(ds):\n",
    "    '''\n",
    "    Restore the dataset data using the dataset attributes.\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : h5py dataset identifier\n",
    "    \n",
    "    Returns:\n",
    "    data : numpy array\n",
    "    '''\n",
    "    ds_attrs = get_ds_attrs(ds)\n",
    "    \n",
    "    _FillValue = get_ds_attribute_value(ds_attrs, '_FillValue')\n",
    "    scale_factor = get_ds_attribute_value(ds_attrs, 'scale_factor')\n",
    "    add_offset = get_ds_attribute_value(ds_attrs, 'add_offset')\n",
    "    \n",
    "    data = ds[()]#.astype('float')\n",
    "    \n",
    "    data = np.where(data != _FillValue, data, np.nan)\n",
    "    if add_offset:\n",
    "        data -= add_offset\n",
    "    if scale_factor:\n",
    "        data *= scale_factor\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(fid):\n",
    "    '''\n",
    "    Return the file coordinates given its identifier object.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    fid : h5py file identifier\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dictionary of latitudes and longitudes and Numpy arrays.\n",
    "    '''\n",
    "    plot_attrs = get_plot_attrs(fid)\n",
    "    \n",
    "    lonW = plot_attrs['GridSpan'][0]\n",
    "    lonE = plot_attrs['GridSpan'][1]\n",
    "    latS = plot_attrs['GridSpan'][2]\n",
    "    latN = plot_attrs['GridSpan'][3]\n",
    "    \n",
    "    lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "    lat_size = plot_attrs['NumberOfLatitudesInGrid']\n",
    "    \n",
    "    lons = np.linspace(lonW, lonE, lon_size)\n",
    "    lats = np.linspace(latS, latN, lat_size)\n",
    "    \n",
    "    return {'lons': lons, 'lats': lats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_dims(ds, coords):\n",
    "    '''\n",
    "    Get dataset dimension names given dataset and coordinates\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : a h5py dataset\n",
    "    coords : dict\n",
    "         a dictionary of coordinates\n",
    "    \n",
    "    Returns\n",
    "    ds_dims : dict\n",
    "         a dctionany\n",
    "   '''\n",
    "    dims = ds.dims\n",
    "    ds_dims = {}\n",
    "    \n",
    "    for i in range(len(dims)):\n",
    "        if dims[i].label == '':\n",
    "            if ds.shape[i] == coords['lons'].size:\n",
    "                ds_dims['lon'] = ds.shape[i]\n",
    "            elif ds.shape[i] == coords['lats'].size:\n",
    "                ds_dims['lat'] = ds.shape[i]\n",
    "        else:\n",
    "            ds_dims[dims[i].label] = ds.shape[i]\n",
    "    \n",
    "    return ds_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coords(dims, coords): \n",
    "    '''\n",
    "    Rearrange coordinates order to match dimensions\n",
    "    shapes for a dataset.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : dict\n",
    "         a dictionary of dimensions\n",
    "    coords : dict\n",
    "         a dictionary of coordinates\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    coords : dict\n",
    "         a dictionary\n",
    "   '''\n",
    "    if list(dims.values())[0] != list(coords.values())[0].size:\n",
    "        temp = coords\n",
    "        coords = {list(coords.keys())[1]: list(coords.values())[1], \n",
    "                  list(coords.keys())[0]: list(coords.values())[0]}\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xarray_dataset_from_file(filename):\n",
    "    '''\n",
    "    Given an OMI HDF5 file name, convert the data into \n",
    "    an Xarray Dataset.\n",
    "       \n",
    "    Parameters\n",
    "    filename : str\n",
    "        HDF5 file name containing OMI data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr_ds : Xarray Dataset\n",
    "    '''\n",
    "    xr_ds = xr.Dataset()\n",
    "    \n",
    "    fid = get_fid(filename)\n",
    "    \n",
    "    data_group = get_data_group(fid)\n",
    "    fid_attrs = get_fid_attrs(fid)   \n",
    "    fid_coords = get_coords(fid)\n",
    "    \n",
    "    for name, hdf_ds in data_group.items():\n",
    "        data = restore_data(hdf_ds)       \n",
    "        ds_attrs = get_ds_attrs(hdf_ds)\n",
    "        \n",
    "        ds_dims = get_ds_dims(hdf_ds, fid_coords)\n",
    "        ds_coords = check_coords(ds_dims, fid_coords)\n",
    "    \n",
    "        xr_ds[name] = xr.DataArray(data, dims = list(ds_dims.keys()), coords = list(ds_coords.values()))\n",
    "        xr_ds[name].attrs = ds_attrs\n",
    "        \n",
    "        \n",
    "    xr_ds.attrs = fid_attrs    \n",
    "       \n",
    "    fid.close()    \n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = create_xarray_dataset_from_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Plotting Our Data</font>\n",
    "\n",
    "File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_GB = file_ds.nbytes / (1024*1024*1024)\n",
    "\n",
    "file_GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = file_ds['RadiativeCloudFraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `matplotlib` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `hvPlot` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More intermediate `hvPlot` plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "var.hvplot.quadmesh('lon', 'lat', \n",
    "                    projection = ccrs.PlateCarree(), \n",
    "                    geo = True, \n",
    "                    ylim = (-60, 80),\n",
    "                    project = True, \n",
    "                    cmap = 'blues', \n",
    "                    #rasterize = True, \n",
    "                    #coastline = True\n",
    "                   )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "var.hvplot.contour('lon', 'lat', \n",
    "                   projection = ccrs.PlateCarree(), \n",
    "                   ylim = (-60, 80),\n",
    "                   cmap = 'reds', \n",
    "                   coastline = True, \n",
    "                   geo = True, \n",
    "                   levels = 9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Read a Collection of Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a collection of OMI daily files for the month of July 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(os.path.join(data_dir, \"OMI-Aura_L3-OMTO3e_2022m07*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(list_files, start=1):\n",
    "    print(f\"{i:<3} --> {os.path.basename(file)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all the files one at the time and create a list of Xarray DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xrds = list()\n",
    "for file in list_files:\n",
    "    list_xrds.append(create_xarray_dataset_from_file(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_xrds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the list of Xarray DataSets into one time series Xarray DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas Series of datetime objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntimes = len(list_files)\n",
    "times = pd.date_range('2022-07-01', freq='1D', periods=ntimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the Xarray DataSets into one time series Xarray DataSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ts = xr.concat(list_xrds, \n",
    "                 dim='time')\n",
    "\n",
    "xr_ts = xr_ts.assign_coords(time=('time', times))\n",
    "xr_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterime the size of the Xarray DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{xr_ts.nbytes / (1024*1024*1024)} Gb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do simple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = \"RadiativeCloudFraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ts[field_name].plot(x=\"lon\", y=\"lat\",\n",
    "                       col=\"time\", col_wrap=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean along longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ts[field_name].mean(dim=\"lon\").plot(x=\"time\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean along longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ts[field_name].mean(dim=[\"lon\", \"lat\"]).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do Time Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ts[field_name].mean(dim=\"time\").plot(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We notice that there are missing values in the latitude range of -65.15 to 75.0.\n",
    "- We can then consider the field only in that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minlat = -65.15\n",
    "maxlat = 75.0\n",
    "RCF = xr_ts[field_name].mean(dim=\"time\").sel(lat=slice(minlat, maxlat))\n",
    "RCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCF.plot(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "subplot_kw = dict(projection=map_projection)\n",
    "fig, ax = plt.subplots(1, 1,\n",
    "                       figsize=(15, 9),\n",
    "                       subplot_kw=subplot_kw)\n",
    "\n",
    "units = '1'\n",
    "cbar_kwargs = {'orientation':'horizontal', \n",
    "               'shrink':0.6, \"pad\" : .05, \n",
    "               'aspect':40, 'label': units}\n",
    "\n",
    "RCF.plot.pcolormesh(ax=ax, x='lon', y='lat',\n",
    "                    transform=data_transform,\n",
    "                    cbar_kwargs=cbar_kwargs,\n",
    "                    add_colorbar=True,\n",
    "                    cmap=\"jet\"\n",
    "                    )\n",
    "# ---> Ticks and labels\n",
    "gl = ax.gridlines(\n",
    "    draw_labels=True, \n",
    "    linewidth=2, color='gray', \n",
    "    alpha=0.5, linestyle='--'\n",
    ")\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "ax.coastlines()\n",
    "plt.title(f\"Time average of {field_name}\", fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "units = '1'\n",
    "cbar_kwargs = {'orientation':'horizontal', \n",
    "               'shrink':0.6, \"pad\" : .05, \n",
    "               'aspect':40, 'label': units}\n",
    "\n",
    "nrows = 16\n",
    "ncols = 2\n",
    "subplot_kw = dict(projection=map_projection)\n",
    "fig, ax = plt.subplots(nrows, ncols,\n",
    "                       figsize=(15, 30),\n",
    "                       subplot_kw=subplot_kw)\n",
    "\n",
    "for i, time_rec in enumerate(xr_ts[field_name].time.values):\n",
    "    RCF = xr_ts[field_name].sel(time=time_rec).sel(lat=slice(minlat, maxlat))\n",
    "\n",
    "    r = i // ncols\n",
    "    c = i - r*ncols\n",
    "    RCF.plot.pcolormesh(ax=ax[r,c], x='lon', y='lat',\n",
    "                    transform=data_transform,\n",
    "                    add_labels=False,\n",
    "                    cmap=\"jet\"\n",
    "                    )\n",
    "\n",
    "    ax[r,c].coastlines()\n",
    "#plt.title(f\"Time series of {field_name}\", fontsize=14);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
