{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading LANDSAT Satellite Data from HDF4 Files Using pyhdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary References/Resources: \n",
    "\n",
    "https://moonbooks.org/Articles/How-to-read-a-MODIS-HDF-file-using-python-/\n",
    "\n",
    "http://fhs.github.io/pyhdf/modules/SD.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from pyhdf.SD import SD, SDS, SDC, SDim, SDAttr   # or import *\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pyHDF Import Context**\n",
    "\n",
    "The `SD` (Scientific Data) class is used for file and top-level info access and implements the HDF SD interface.\n",
    "\n",
    "The `SDS` (Scientific Dataset) class is used for dataset objects.\n",
    "\n",
    "The `SDC` (Scientific Data Constants) class holds the constants that define file opening modes and data types.\n",
    "\n",
    "The `SDim` (Scientific Data Dimensions) class is used for dimension objects.\n",
    "\n",
    "The `SDAttr` (Scientific Data Attributes) class is used for attribute objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles off alphabetical sorting\n",
    "pprint.sorted = lambda x, key=None:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample HDF4 Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample LANDSAT satellite data\n",
    "filePath = \"/Users/deonkouatchou/eviz/eviz_datasource_dev/Samples/LANDSAT/\"\n",
    "\n",
    "file1 = filePath + \"LT50830152011198GLC00.hdf\"\n",
    "file2 = filePath + \"LT50830152011214GLC00.hdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LANDSAT Naming Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gisgeography.com/landsat-file-naming-convention/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening file for reading\n",
    "fid = SD(file1, SDC.READ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some file information (not data) only work if attributes exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Author:\", fid.author)\n",
    "# print(\"Priority:\", fid.priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number indicates the number of datasets in the file (not to be confused w/ xarray datasets) while the second number indicates the number of attributes attached to the global file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the file attributes which hold important global metadata.\n",
    "\n",
    "Some notable ones are the data provider, satellite name and instrument, coordinate boundaries, and structural metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pprint returns the information in a more readable format\n",
    "pprint.pprint(fid.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the datasets' names and basic info such as shape and dimension labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(fid.datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index and name of the datasets\n",
    "datasets_dict = fid.datasets()\n",
    "\n",
    "for index, name in enumerate(datasets_dict.keys()):\n",
    "    print(index, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction as NumPy Arrays\n",
    "\n",
    "Let's assume that we want to extract data from the field `sr_band4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select()` method from the `SD` class allows us to extract a dataset (object) given it's name or index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = fid.select('sr_band4') # selects a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this doesn't get us the data, the `info()` function in the `SDS` class allows us to get the dataset name, rank (or level with file-leve being rank 1), dimension lengths, data type, and number of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve and store the data itself as a NumPy array using the `get()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds.get() # gets the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirms that the data has been stored as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Class Type: \", type(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like any NumPy array, we can get the shape and dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA TYPES\n",
    "\n",
    "0 - SDC.UNLIMITED: dimensions only; they can grow dynamically\n",
    "\n",
    "3 - SDC.UCHAR; SDC.UCHAR8: unsigned 8-bit integer\n",
    "\n",
    "4 - SDC.CHAR; SDC.CHAR8: 8-bit character\n",
    "\n",
    "5 - SDC.FLOAT32: 32-bit floating point\n",
    "\n",
    "6 - SDC.FLOAT64: 64-bit floating point\n",
    "\n",
    "20 - SDC.INT8: signed 8-bit integer\n",
    "\n",
    "21 - SDC.UINT8: unsigned 8-bit integer\n",
    "\n",
    "22 - SDC.INT16: signed 16-bit integer\n",
    "\n",
    "23 - SDC.UINT16: unsigned 16-bit integer\n",
    "\n",
    "24 - SDC.INT32: signed 32-bit integer\n",
    "\n",
    "25 - SDC.UINT32: unsigned 32-bit integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "There are three levels of attributes:\n",
    "\n",
    "• **File** or **global** attributes\n",
    "\n",
    "• **Dataset** or **data** attributes\n",
    "\n",
    "• **Dimension** attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Attributes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring back to the file attributes from the beginning, these hold a lot of important information that provide context to the dataset and file origins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_attrs = fid.attributes()\n",
    "pprint.pprint(global_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the actual attribute objects using the `attr()` function from the `SD` class.\n",
    "\n",
    "But unlike other instances, the `info()` function from the `SDAttr` class actually doesn't give us much helpful info other than the attribute data type (reference table) and the length (within data type context).\n",
    "\n",
    "The `index()` function from the `SDAttr` class returns the attribute object index while the `get()` function returns the object value. Given our access to the dictionary from the `SD` class, however, these functions might not be utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(global_attrs)):\n",
    "    print(fid.attr(i).info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Attributes**\n",
    "\n",
    "Let's refer back to our `sample_ds` variable which holds the `sr_band4` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the file-level `SD` class, the `SDS` class' `attributes()` method returns a dictionary of the attributes' names and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(sample_ds.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important information such as fill values, scale factors, and offset values are found in dataset attributes and will be important to fully restoring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values (also a reset if testing different datasets/variables)\n",
    "fill = None\n",
    "scale = 1\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sample_ds.attributes().items():\n",
    "    if key == '_FillValue':\n",
    "        fill = value  \n",
    "    if key == 'scale_factor':\n",
    "        scale = value\n",
    "    if key == 'add_offset':\n",
    "        offset = value\n",
    "# data = data * scale + offset\n",
    "    \n",
    "print('Fill Value:', fill)\n",
    "print('Scale Factor:', scale)\n",
    "print('Offset:', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `SDS` class, we can also access the dimension names and sizes using the `dimensions()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is nice, the dictionary above does not allow us to access actual dimension objects and the other information that they may hold. To access the objects, we can use the `dim()` function from the `SDS` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dims = list()   # Will actually hold dimension objects\n",
    "\n",
    "for i in range(len(sample_ds.dimensions())):\n",
    "    sample_dims.append(sample_ds.dim(i))\n",
    "    \n",
    "sample_dims = tuple(sample_dims)\n",
    "\n",
    "sample_dims   # Can confirm dimension objects exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see that we can access not only the labels and size but also the units, scale data type, and number of attributes. We can even access the attributes similarly to the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sample_dims)):\n",
    "    print(f\"Dimension {i+1}\")\n",
    "    print(\"\\tInfo:\", sample_dims[i].info())\n",
    "    print(\"\\tLength:\", sample_dims[i].length())\n",
    "    print(\"\\tAttributes: \", sample_dims[i].attributes())\n",
    "    \n",
    "    # You can access other dim attrs if they exist by this given struture: dim1.attr_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** * Note from the data type table that dimensions exclusively may have the value 0 or a `SDC.UNLIMITED` data type. This just means that they can grow dynamically **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pyHDF, it is possible that coordinates (known as dimension scales) are actually stored as datasets. Thankfully, the `SDS` class provides the `iscoordvar()` function to determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bool(sample_ds.iscoordvar()))\n",
    "\n",
    "# If there was a scale, it would be accessible via: dim1.getscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to traverse through all the datasets and see if one of them holds coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_sets = list()   # Will hold datasets suspected to be coordinates\n",
    "\n",
    "for i in range(len(fid.datasets())):\n",
    "    ds = fid.select(i)\n",
    "    if ds.iscoordvar()):\n",
    "        coord_sets.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible that some coordinate information is stored as a file attribute. If we go back once more to our global attribute dictionary, we can see some keys such as corner and bounding coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(fid.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then traverse through it and extract and attributes that may be related to the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_attrs = {}   # Will hold coordinate-related attributes\n",
    "for key, value in fid.attributes().items():\n",
    "    if 'coordinate' in key.lower() or 'latlong' in key.lower():\n",
    "        coord_attrs[key] = value\n",
    "\n",
    "coord_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these attributes, it would be much easier to work with our bounding coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now go back to our datasets, we can see that thankfully, they all have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for vals in fid.datasets().values():\n",
    "    print(f\"Dataset {count} Shape:\", vals[0:2])\n",
    "    count += 1\n",
    "    shape = vals[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bounding coordinates and the shape, we can artificially create our full coordinates; however, this is under the assumption that the datasets truly align with this artificial system. This means that we can't confirm its accuracy.\n",
    "\n",
    "The first step would be to assign our boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in coord_attrs.keys():\n",
    "    if 'north' in key.lower():\n",
    "        latN = coord_attrs[key]\n",
    "    if 'south' in key.lower():\n",
    "        latS = coord_attrs[key]\n",
    "    if 'east' in key.lower():\n",
    "        lonE = coord_attrs[key]\n",
    "    if 'west' in key.lower():\n",
    "        lonW = coord_attrs[key]\n",
    "\n",
    "print(\"North:\", latN)\n",
    "print(\"South:\", latS)\n",
    "print(\"East:\", lonE)\n",
    "print(\"West:\", lonW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would create our spacing using the dataset shapes and boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our coords. 'lats' can be substituted for 'y' and 'lons' for 'x'\n",
    "lat_space = (latN - latS) / shape[0]\n",
    "lon_space = (lonE - lonW) / shape[1]\n",
    "\n",
    "print(lat_space, \"|\", lon_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally create our coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.linspace(latS, latN, shape[0])\n",
    "lons = np.linspace(lonW, lonE, shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Latitudes:\\n', lats)\n",
    "print('Longitudes:\\n', lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now close our file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conversion to XArray DataArrays and Datasets\n",
    "\n",
    "Now that we've been able to get all of the necessary information to create an XArray Dataset, we can start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: NOT UP-TO-DATE WITH FUNCTIONS USED IN EVIZ/IVIZ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Parameter(s): a file name (str)\n",
    "    Return Type(s): an SD object (file identifier)\n",
    "    Function: returns our file reader object\n",
    "'''\n",
    "def get_fid(sample_file):\n",
    "    sample_fid = SD(sample_file, SDC.READ)\n",
    "    return sample_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing File Attrs: fid.attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Dataset Attrs: ds.attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing fill, scale, offset\n",
    "'''\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): float, int, or None\n",
    "    Function: returns fill value of a given dataset object\n",
    "'''\n",
    "def get_fill(sample_ds):\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == '_FillValue':\n",
    "            return value \n",
    "    return None\n",
    "\n",
    "'''\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): float, int, or None\n",
    "    Function: returns scale factor of a given dataset object\n",
    "'''\n",
    "def get_scale(sample_ds):\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == 'scale_factor':\n",
    "            return value \n",
    "    return 1\n",
    "\n",
    "'''\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): float, int, or None\n",
    "    Function: returns offset value of a given dataset object\n",
    "'''\n",
    "def get_offset(sample_ds):\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == 'add_offset':\n",
    "            return value \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Dataset Data: ds.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring Data\n",
    "'''\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): NumPy array\n",
    "    Function: restores data of a given dataset object\n",
    "'''\n",
    "def restore_data(sample_ds):\n",
    "    fill = get_fill(sample_ds)\n",
    "    scale = get_scale(sample_ds)\n",
    "    offset = get_offset(sample_ds)\n",
    "    \n",
    "    data = sample_ds.get()#.astype('float')\n",
    "    \n",
    "    data = np.where(data != fill, data, np.nan)\n",
    "    data *= scale\n",
    "    data += offset\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Dims:\n",
    "'''\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): Python list of SDim objects\n",
    "    Function: returns dimension objects of a given dataset object\n",
    "'''\n",
    "def get_dims(sample_ds):\n",
    "    sample_dims = []   # Will actually hold dimension objects\n",
    "    \n",
    "    for i in range(len(sample_ds.dimensions())):\n",
    "        sample_dims.append(sample_ds.dim(i))\n",
    "        \n",
    "    return sample_dims\n",
    "\n",
    "# Accessing Dim Attrs\n",
    "'''\n",
    "    Parameter(s): SDim object\n",
    "    Return Type(s): Python Dict\n",
    "    Function: returns attributes of a given dimension object\n",
    "'''\n",
    "def get_dim_attrs(dim):\n",
    "    attrs = {}   # Will hold dim attrs\n",
    "    \n",
    "    attrs['Given Name'] = dim.info()[0]\n",
    "    attrs['dtype'] = dim.info()[2]\n",
    "    attrs.update(dim.attributes())   # Adds other unknown attributes\n",
    "    \n",
    "    return attrs\n",
    "\n",
    "def get_dims_attrs(ds):\n",
    "    dims_attrs = {}\n",
    "    dims = get_dims(ds)\n",
    "    \n",
    "    for dim in dims:\n",
    "        if dim.info()[0] == 'YDim':\n",
    "            dims_attrs['lat'] = get_dim_attrs(dim)\n",
    "        elif dim.info()[0] == 'XDim':\n",
    "            dims_attrs['lon'] = get_dim_attrs(dim)\n",
    "            \n",
    "    return dims_attrs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Coords: lats, lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing File-level Coords\n",
    "'''\n",
    "    Parameter(s): SD object\n",
    "    Return Type(s): boolean\n",
    "    Function: returns false if there are no file-level coords and true if there are\n",
    "    ** Should be modified to return list of file-level coords if there are any\n",
    "'''\n",
    "def get_fid_coords(sample_fid):\n",
    "    coord_sets = []   # will hold datasets suspected to be coordinates\n",
    "\n",
    "    for i in range(len(sample_fid.datasets())):\n",
    "        sample_ds = sample_fid.select(i)\n",
    "        if bool(sample_ds.iscoordvar()):\n",
    "            coord_sets.append(sample_ds)\n",
    "\n",
    "    if len(coord_sets) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Parameter(s): SD object\n",
    "    Return Type(s): Python dict of String keys and numeric items\n",
    "    Function: returns coord boundaries from file-level attrs to construct coords at dataset level\n",
    "'''\n",
    "def get_coord_bounds(sample_fid):\n",
    "    coord_attrs = {}    \n",
    "    # Gets our coordinate-related attributes\n",
    "    for key, value in sample_fid.attributes().items():\n",
    "        if 'coordinate' in key.lower():\n",
    "            coord_attrs[key] = value \n",
    "        \n",
    "    coord_bounds = {}\n",
    "    # Gets our coordinate bounds\n",
    "    for key in coord_attrs.keys():\n",
    "        if 'north' in key.lower():\n",
    "            coord_bounds['latN'] = coord_attrs[key]\n",
    "        if 'south' in key.lower():\n",
    "            coord_bounds['latS'] = coord_attrs[key]\n",
    "        if 'east' in key.lower():\n",
    "            coord_bounds['lonE'] = coord_attrs[key]\n",
    "        if 'west' in key.lower():\n",
    "            coord_bounds['lonW'] = coord_attrs[key]    \n",
    "    \n",
    "    return coord_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Dataset-level Coords\n",
    "'''\n",
    "    Parameter(s): an SD and an SDS object\n",
    "    Return Type(s): Python dict of String keys and NumPy array items\n",
    "    Function: returns constructed dataset given the file ID object and a particular dataset\n",
    "'''\n",
    "def get_ds_coords(sample_fid, sample_ds):\n",
    "    sample_bounds = get_coord_bounds(sample_fid)\n",
    "    \n",
    "    latN = sample_bounds['latN']\n",
    "    latS = sample_bounds['latS']\n",
    "    lonE = sample_bounds['lonE']\n",
    "    lonW = sample_bounds['lonW']\n",
    "    \n",
    "    lat_shape = sample_ds.dimensions()['YDim']\n",
    "    lon_shape = sample_ds.dimensions()['XDim']\n",
    "    \n",
    "    if isinstance(sample_bounds, dict):   # Have to configure dataset coords\n",
    "        lat_space = (latN - latS) / lat_shape\n",
    "        lon_space = (lonE - lonW) / lon_shape\n",
    "        \n",
    "        lats = np.linspace(latS, latN + lat_space, lat_shape)\n",
    "        lons = np.linspace(lonW, lonE + lon_space, lon_shape)\n",
    "        \n",
    "        sample_coords = {'lats': lats, 'lons': lons}\n",
    "        return sample_coords\n",
    "        \n",
    "    #else:   # Coords already set at file level\n",
    "        #return sample_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our XArray Dataset:\n",
    "'''\n",
    "    Parameter(s): file name (str)\n",
    "    Return Type(s): XArray Dataset\n",
    "    Function: reads a LANDSAT HDF4 file and returns an XArray dataset\n",
    "'''\n",
    "def read_file(file):\n",
    "    fid = get_fid(file)\n",
    "    \n",
    "    if get_fid_coords(fid):   # File-level coords exist\n",
    "        pass\n",
    "    else:\n",
    "        fid_coords = False    # File-level coords do not exist   \n",
    "    \n",
    "    xr_ds = xr.Dataset()\n",
    "    \n",
    "    for name in fid.datasets().keys():\n",
    "        ds = fid.select(name)\n",
    "        \n",
    "        coords_dict = get_ds_coords(fid, ds)\n",
    "        lats = coords_dict['lats']\n",
    "        lons = coords_dict['lons']\n",
    "        \n",
    "        xr_ds[name] = xr.DataArray(restore_data(ds), coords = [lats, lons], dims = ['lat', 'lon'])\n",
    "        \n",
    "        xr_ds[name].attrs = ds.attributes()\n",
    "        \n",
    "        dims = get_dims(ds)\n",
    "        for dim in dims:\n",
    "            if dim.info()[0] == 'YDim':\n",
    "                xr_ds[name].lat.attrs = get_dim_attrs(dim)\n",
    "            elif dim.info()[0] == 'XDim':\n",
    "                xr_ds[name].lon.attrs = get_dim_attrs(dim)\n",
    "    \n",
    "    xr_ds.attrs = fid.attributes()\n",
    "    \n",
    "    fid.end()\n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_ds = read_file(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_MB = file1_ds.nbytes / 1000000\n",
    "\n",
    "file1_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = file1_ds['toa_band6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `matplotlib` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot()   # Doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intermediate `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot.quadmesh('lon', 'lat', xlim = (-172.5, -166.75), ylim = (63, 65.3), geo = True, project = True,\n",
    "                    rasterize = True, projection = ccrs.PlateCarree(), features = ['borders'], coastline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_ds = read_file(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_MB = file2_ds.nbytes / 1000000\n",
    "\n",
    "file2_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = file2_ds['toa_band6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `matplotlib` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intermediate `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot.contourf('lon', 'lat', xlim = (-172.5, -166.75), ylim = (63, 65.3), geo = True, levels = 10,\n",
    "                    cmap = 'plasma', projection = ccrs.PlateCarree(), features = ['borders'], coastline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved from first resource\n",
    "\n",
    "\"\"\"\n",
    "If there were latitude and longitude data\n",
    "\n",
    "# Read dataset.\n",
    "DATAFIELD_NAME='RelHumid_A'\n",
    "data3D = hdf.select(DATAFIELD_NAME)\n",
    "data = data3D[11,:,:]\n",
    "\n",
    "# Read geolocation dataset.\n",
    "lat = hdf.select('Latitude')\n",
    "latitude = lat[:,:]\n",
    "lon = hdf.select('Longitude')\n",
    "longitude = lon[:,:]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
