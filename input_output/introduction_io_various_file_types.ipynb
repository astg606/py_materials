{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhdP-jQAdkXV"
   },
   "source": [
    "<center><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\"></center>\n",
    "\n",
    "<center>\n",
    "<h1><font size=\"+3\">GSFC Python Bootcamp</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "<h2>\n",
    "<font color=\"red\"> \n",
    "File Manipulation and Usage <br> \n",
    "within <br> \n",
    "Science and Engineering Applications\n",
    "</font> \n",
    "</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Os9mQotpvQEo",
    "outputId": "5066d114-e418-422f-a225-f0e562d35d9c"
   },
   "outputs": [],
   "source": [
    "# data downloads for this lesson\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# obtain jpg file from online\n",
    "url = 'https://blog.lipsumarium.com/assets/img/posts/2017-07-22-caption-memes-in-python/one-does-not-simply-make-a-good-meme-generator-in-python.jpg'\n",
    "urllib.request.urlretrieve(url, \"meme.jpg\")\n",
    "\n",
    "# this file contains a list of Winter Olympic Medals and details\n",
    "urllib.request.urlretrieve('http://winterolympicsmedals.com/medals.csv', \"medals.csv\")\n",
    "\n",
    "# obtain JSON file from online\n",
    "f = 'https://services.swpc.noaa.gov/json/solar_probabilities.json'\n",
    "urllib.request.urlretrieve(f, 'probabilities.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ra57zfMzggrh"
   },
   "source": [
    "# 1. The Basics\n",
    "\n",
    "---\n",
    "\n",
    "## 1.a Manipulating ASCII/Text Files\n",
    "\n",
    "#### Create a file\n",
    "```python\n",
    "f = open('filename.txt', 'w')\n",
    "f.write(data) # type(data) == str\n",
    "f.close()\n",
    "\n",
    "with open('filename.txt', 'w') as f:\n",
    "     f.write(data) # writeline(s) as well\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = [105.5, 67.25, 13.75, 86.20, 45.80]\n",
    "lats = [-22.72, -43.56, 30.41, 75.57, 11.60]\n",
    "\n",
    "with open('sample_text_file.txt', 'w') as f:\n",
    "     for a, b in zip(lons,lats):\n",
    "         f.write(str(a)+'  '+ str(b)+'\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sample_text_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Read a file\n",
    "```python\n",
    "f = open('filename.txt', 'r')\n",
    "data = f.read() # readline(s) as well\n",
    "f.close()\n",
    "\n",
    "with open('filename.txt', 'r') as f:\n",
    "     data = f.read() # we can also use other modes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_text_file.txt', 'r') as f:\n",
    "     lines = f.readlines()\n",
    "        \n",
    "print(lines)\n",
    "for line in lines:\n",
    "    a,b = line.split()\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Manipulating Binary Files\n",
    "\n",
    "```python\n",
    "with open('filename.bin', 'rb') as f:\n",
    "     data = f.read() # read without decoding\n",
    "```\n",
    "\n",
    "If you had a Binary file with mixed data types of known formats, you would then use the [`struct`](https://docs.python.org/3/library/struct.html) function to aid you in decoding binary data. Imagery files such as JPG, PNG, etc. can be read directly using the binary mode of Python, but this can be very tedious as well as not a viable option to read image data.\n",
    "\n",
    "_Warning:_ Be careful about the endianness of your files! (Big or little)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = [105.5, 67.25, 13.75, 86.20, 45.80]\n",
    "lats = [-22.72, -43.56, 30.41, 75.57, 11.60]\n",
    "\n",
    "import struct\n",
    "with open('sample_bin_file.dat', 'wb') as f:\n",
    "     for i in range(len(lons)):\n",
    "         f.write(struct.pack('d', lons[i]))\n",
    "         f.write(struct.pack('d', lats[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = []\n",
    "with open('sample_bin_file.dat', 'rb') as fid:\n",
    "     i = 0\n",
    "     nBytes = struct.calcsize('d')\n",
    "     while True:\n",
    "           rec = fid.read(nBytes)\n",
    "           if len(rec) != nBytes:\n",
    "              break\n",
    "           (y,) = struct.unpack('d', rec)\n",
    "           ya.append(y)\n",
    "           i += 1\n",
    "\n",
    "import numpy as np\n",
    "ya = np.array(ya)\n",
    "ya.shape = (5,2)\n",
    "print(ya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcbNIjkbg0G9"
   },
   "source": [
    "Take for example, the following image:\n",
    "\n",
    "![meme](https://blog.lipsumarium.com/assets/img/posts/2017-07-22-caption-memes-in-python/one-does-not-simply-make-a-good-meme-generator-in-python.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuykVdjdhKb8"
   },
   "outputs": [],
   "source": [
    "with open('meme.jpg', 'rb') as f:\n",
    "     data = f.read()\n",
    "  \n",
    "print(data[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mldyowuAh3lY"
   },
   "source": [
    "Here, we have read an imagery file in binary mode, but have not decoded this binary string into numbers, text, or whatever else we desire. Other packages such as PIL (Python Imaging Library) exist for those inclined which you should use instead the fork called [Pillow](https://python-pillow.org/). The more advanced and popular [OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html) would aid in doing [image manipulation](https://docs.python-guide.org/scenarios/imaging/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tp1bs9XckCfm"
   },
   "source": [
    "# 2. Other File Types (Standard Packages)\n",
    "\n",
    "---\n",
    "\n",
    "Beyond document-based reading and writing of file data, what other types of data are there?\n",
    "\n",
    "## 2a. CSV\n",
    "\n",
    "Comma-separated value files are similar to spreadsheets and tabular/formatted data and used widely in the engineering and financial disciplines. In Python, we can read these directly using the `csv` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yERoJigqlDiO"
   },
   "outputs": [],
   "source": [
    "# this file contains a list of Winter Olympic Medals and details\n",
    "!head medals.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2La7-h5ylaq0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "cr = csv.reader(open('medals.csv')) # there is also a writer to write csv files\n",
    "\n",
    "records = 0 # just need a counter to limit output\n",
    "for row in cr:\n",
    "    print(row)  \n",
    "    if records != 10:\n",
    "       records += 1\n",
    "    else:\n",
    "       break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7G0kOdinKbP"
   },
   "source": [
    "We can also use [NumPy](https://github.com/pytrain/numpy/blob/master/IntroNumPy.ipynb) or [Pandas](https://github.com/pytrain/pandas/blob/master/Intro_Pandas.ipynb) or other packages to read this file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsvzMjiYm8Qh"
   },
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "year = np.loadtxt('medals.csv', delimiter=',', \n",
    "                  usecols=(0), unpack=True, skiprows=1)\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# only 10 rows of data will be displayed\n",
    "pd.set_option(\"max_rows\", 10) \n",
    "# print floating point numbers using fixed point notation,\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Pandas\n",
    "data = pd.read_csv('medals.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZx8nO85l1wu"
   },
   "source": [
    "# 2b. JSON\n",
    "\n",
    "---\n",
    "\n",
    "JavaScript Object Notion is basically a dictionary or list of dictionaries put into an ASCII/Text file or streamed directly. They are mainly used in web programming and with JavaScript for passing data between websites and the user. Like, CSV, Python contains a direct package to read this type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_SXDGQxo6s8"
   },
   "source": [
    "The following data is the solar event probabilities from the Space Weather Prediction Center. This aids scientists in determining if there will be a solar event that could either cause damage to space-based instruments or impact other Earth-based instrumentation like GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNAi_mzRozz1"
   },
   "outputs": [],
   "source": [
    "!cat probabilities.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvqEHyyO1KzL"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('probabilities.json') as f:\n",
    "     data = json.loads(f.read())\n",
    "  \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxem86We1OJv"
   },
   "source": [
    "Or, if we wanted to have some fun, we could continually find the location of the International Space Station:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "GlAss1OYmXb1",
    "outputId": "970982cb-dd6c-4fa1-8619-c50000bbd018"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "i = 0\n",
    "while i < 10:\n",
    "  response = urllib.request.urlopen(\"http://api.open-notify.org/iss-now.json\")\n",
    "  obj = json.loads(response.read())\n",
    "  \n",
    "  t = dt.datetime.utcfromtimestamp(obj['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "  \n",
    "  print('time: ', t, ', position: (',\n",
    "        obj['iss_position']['latitude'], ' ,', obj['iss_position']['longitude'],\n",
    "        ')', end='')\n",
    "  \n",
    "  time.sleep(5)\n",
    "  i += 1\n",
    "  print('\\r', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIwPsQGunPjj"
   },
   "source": [
    "We can also use Pandas to read this file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy38f9OHqY9X"
   },
   "outputs": [],
   "source": [
    "pd.read_json('probabilities.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yp9_bSut73T4"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SWVPwWtB8cC"
   },
   "source": [
    "I'd like to find out the list of airbus flights and their properties of the aircraft. Download, read, and plot the points of the aircraft track.\n",
    "\n",
    "\n",
    "CSV File: https://opensky-network.org/datasets/states/airbus_tree.csv\n",
    "\n",
    "It's hard to test your knowledge of these packages as they are so simple and reading data is usually a preliminary step for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "dT2C4opPExrX"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://opensky-network.org/datasets/states/airbus_tree.csv')\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for flight in data:\n",
    "    plt.plot(data['lat'], data['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzaTScL1osPq"
   },
   "source": [
    "# 3. Other File Types (Non-Standard)\n",
    "\n",
    "---\n",
    "\n",
    "Beyond these multi-disciplinary file types, there are other file types that exists that are specific to a research area or data source.\n",
    "\n",
    "\n",
    "## 3a. Earth Science (HDF-5 / netCDF4)\n",
    "\n",
    "Due to the nature of the data produced by Earth Science models, one would need to store time-dependent data within files that can be grouped or put into a particular type of hierachy. HDF-5 is the base file type for this hierarchical data type and netCDF4 is a reduced version limiting to the groups to just one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Manipulating NetCDF Files </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UM0PjOROHILD"
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "#from numpy.random import uniform\n",
    "\n",
    "#------------------\n",
    "# Creating the file\n",
    "#------------------\n",
    "with Dataset('my_file.nc4', mode='w', format='NETCDF4') as ncFid:\n",
    "     print(ncFid.file_format)\n",
    "\n",
    "     #------------------------\n",
    "     # Defining the dimensions\n",
    "     #------------------------\n",
    "     time = ncFid.createDimension('time', None)\n",
    "     lev  = ncFid.createDimension('lev', 72)\n",
    "     lat  = ncFid.createDimension('lat', 91)\n",
    "     lon  = ncFid.createDimension('lon', 144)\n",
    "\n",
    "     print(ncFid.dimensions)\n",
    "\n",
    "     #------------------------------------------\n",
    "     # Creating variables and Setting attributes\n",
    "     #------------------------------------------\n",
    "     times = ncFid.createVariable('time','f8',('time',))\n",
    "     times.units = 'hours since 0001-01-01 00:00:00.0'\n",
    "     times.calendar = 'gregorian'\n",
    "\n",
    "     levels = ncFid.createVariable('lev','i4',('lev',))\n",
    "     levels.units = 'hPa'\n",
    "\n",
    "     latitudes = ncFid.createVariable('lat','f4',('lat',))\n",
    "     latitudes.units = 'degrees north'\n",
    "\n",
    "     longitudes = ncFid.createVariable('lon','f4',('lon',))\n",
    "     longitudes.units = 'degrees east'\n",
    "\n",
    "     temp = ncFid.createVariable('temp','f4',('time','lev','lat','lon',))\n",
    "     temp.units = 'K'\n",
    "\n",
    "     ncFid.description = 'Sample netCDF file'\n",
    "     ncFid.source      = 'netCDF4 python tutorial'\n",
    "     ncFid.history     = 'Created on June 18, 2019'\n",
    "\n",
    "     #---------------\n",
    "     # Setting values\n",
    "     #---------------\n",
    "     latitudes[:]  =  np.arange(-90,91,2.0)\n",
    "     longitudes[:] =  np.arange(-180,180,2.5)\n",
    "     levels[:]     =  np.arange(0,72,1)\n",
    "     temp[0:5,:,:,:] = 300*np.random.uniform(\\\n",
    "         size=(5,levels.size,latitudes.size, longitudes.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Dataset('my_file.nc4', mode='r') as ncFid:\n",
    "     temp = ncFid.variables['temp'][:]\n",
    "\n",
    "print(temp.shape)\n",
    "print(np.mean(temp), np.std(temp), np.max(temp), np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "cs = plt.contourf(temp[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Manipulating HDF5 Files </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVgxsmdTpr53"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# gzip compression flag\n",
    "comp = 6\n",
    "\n",
    "#------------------\n",
    "# Creating the file\n",
    "#------------------\n",
    "with h5py.File('my_file.h5', 'w') as hFid:\n",
    "     #----------------\n",
    "     # File attributes\n",
    "     #----------------\n",
    "     hFid.attrs['source']      = 'H5Py Tutorial'\n",
    "     hFid.attrs['history']     = 'Created on June 18, 2019'\n",
    "     hFid.attrs['description'] = 'Sample HDF5 file'\n",
    "\n",
    "     #------------------------\n",
    "     # Defining the dimensions\n",
    "     #------------------------\n",
    "     lat = np.arange(-90,91,2.0)\n",
    "     dset = hFid.require_dataset('lat', \n",
    "                                 shape=lat.shape, \n",
    "                                 dtype=np.float32, compression=comp)\n",
    "     dset[...] = lat\n",
    "     dset.attrs['name'] = 'latitude'\n",
    "     dset.attrs['units'] = 'degrees north'\n",
    "\n",
    "     lon = np.arange(-180,180,2.5)\n",
    "     dset = hFid.require_dataset('lon', shape=lon.shape, dtype=np.float32, compression=comp)\n",
    "     dset[...] = lon\n",
    "     dset.attrs['name'] = 'longitude'\n",
    "     dset.attrs['units'] = 'degrees east'\n",
    "\n",
    "     lev = np.arange(0,72,1)\n",
    "     dset = hFid.require_dataset('lev', shape=lev.shape, dtype=np.int, compression=comp)\n",
    "     dset[...] = lev\n",
    "     dset.attrs['name'] = 'vertical levels'\n",
    "     dset.attrs['units'] = 'hPa'\n",
    "\n",
    "     time = np.arange(0,5,1)\n",
    "     dset = hFid.require_dataset('time', shape=time.shape, maxshape=(None), dtype=np.float32, compression=comp)\n",
    "     dset[...] = time\n",
    "     dset.attrs['name'] = 'time'\n",
    "     dset.attrs['units'] = 'hours since 2013-01-01 00:00:00.0'\n",
    "     dset.attrs['calendar'] = 'gregorian'\n",
    "\n",
    "     #------------------------------------------\n",
    "     # Creating variables and Setting attributes\n",
    "     #------------------------------------------\n",
    "     arr = np.zeros((5,lev.size,lat.size,lon.size))\n",
    "     arr[0:5,:,:,:] = 300*np.random.uniform(\n",
    "                    size=(5,lev.size,lat.size,lon.size))\n",
    "     dset = hFid.require_dataset('temp', shape=arr.shape, \n",
    "                                 dtype=np.float32, compression=comp)\n",
    "     dset[...] = arr\n",
    "     dset.attrs['name'] = 'temperature'\n",
    "     dset.attrs['units'] = 'K'\n",
    "\n",
    "     #---------------\n",
    "     # Creating Groups \n",
    "     #---------------\n",
    "     gpData2D = hFid.create_group('2D_Data')\n",
    "     sgpLand  = gpData2D.create_group('2D_Land')\n",
    "     sgpSea   = gpData2D.create_group('2D_Sea')\n",
    "\n",
    "     gpData3D = hFid.create_group('3D_Data')\n",
    "\n",
    "     #----------------------\n",
    "     # Write data in a group\n",
    "     #----------------------\n",
    "     temp = gpData3D.create_dataset('temp', data=arr)\n",
    "     temp.attrs['name'] = 'temperature'\n",
    "     temp.attrs['units'] = 'K'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('my_file.h5', 'r') as hFid:\n",
    "     print(hFid.keys())\n",
    "\n",
    "     lev  = hFid['lev'].value\n",
    "     lat  = hFid['lat'].value\n",
    "     lon  = hFid['lon'].value\n",
    "     time = hFid['time'].value\n",
    "\n",
    "     temp1 = hFid['temp'].value\n",
    "     print(temp1[0,0,0,0], temp1[4,6,7,15])\n",
    "\n",
    "     temp2 = hFid['3D_Data']['temp'].value\n",
    "     print(temp2[0,0,0,0], temp2[4,6,7,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGGxrwWEqbA0"
   },
   "source": [
    "In addition to this hierarchical raw data format for Earth Science data, there is also GIS application data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Manipulating Shapefile Files </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# Get the file name from the natural_earth database\n",
    "shpfilename = shpreader.natural_earth(resolution='110m',\n",
    "                                      category='cultural',\n",
    "                                      name='admin_0_countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and get countries \n",
    "reader = shpreader.Reader(shpfilename)\n",
    "countries = reader.records()\n",
    "next_country = next(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(next_country.attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print features of a country\n",
    "for key in next_country.attributes:\n",
    "    print(\"{:} --> {:}\".format(key,country.attributes[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define a function which returns the population given the country\n",
    "population = lambda country: country.attributes['POP_EST']\n",
    "\n",
    "# Countries sorted py population\n",
    "countries_sorted_by_population = sorted(reader.records(), \\\n",
    "                                         key=population)\n",
    "\n",
    "num_countries = len(countries_sorted_by_population)\n",
    "n = 5\n",
    "\n",
    "# Get the first 5 most populated\n",
    "most_populated = countries_sorted_by_population[num_countries-n:]\n",
    "\n",
    "print(\"Most Populated Countries\")\n",
    "for nation in most_populated:\n",
    "    print(\"   {:>} --> {:>}\".format(nation.attributes['NAME_LONG'], \\\n",
    "                               nation.attributes['POP_EST']))\n",
    "\n",
    "# Get the 5 least populated\n",
    "least_populated = countries_sorted_by_population[:n]\n",
    "\n",
    "print()\n",
    "print(\"Least Populated Countries\")\n",
    "for nation in least_populated:\n",
    "    print(\"   {:>} --> {:>}\".format(nation.attributes['NAME_LONG'], \\\n",
    "                               nation.attributes['POP_EST']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "# Select the map projection\n",
    "#----------------------\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    " \n",
    "# Select the area of interest\n",
    "#-----------------------\n",
    "ax.set_extent([-150, 60, -25, 60])\n",
    " \n",
    "for country in countries:\n",
    "    if country.attributes['ADM0_A3'] == 'USA':\n",
    "        ax.add_geometries(country.geometry, ccrs.PlateCarree(), \\\n",
    "                          facecolor=(0, 0, 1),\n",
    "                          label=country.attributes['ADM0_A3'])\n",
    "    else:\n",
    "        ax.add_geometries(country.geometry, \\\n",
    "                          ccrs.PlateCarree(), \\\n",
    "                          facecolor=(0, 1, 0), \\\n",
    "                          label=country.attributes['ADM0_A3'])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSZCyMEbqBLk"
   },
   "source": [
    "## 3b. Space Science (Astronomy, Heliophysics, etc.) - FITS Files\n",
    "\n",
    "FITS (Flexible Image Transport System) files contains imagery and the metadata associated with the imagery that is found in the file. FITS is a standard data format used within astronomy and is endorsed by [GSFC NASA](http://fits.gsfc.nasa.gov/) and the IAU (International Astronomical Union).\n",
    "\n",
    "Most FITS files when opened from a web browser shows a header of ASCII (human readible) giving the details or descriptions of the data contained within the file.\n",
    "\n",
    "> Sample Files:  \n",
    ">  \n",
    "> There are samples within the package AstroPy and some distributed online through GSFC. [Here](http://fits.gsfc.nasa.gov/fits_samples.html) is a link to those samples provided by GSFC.\n",
    "\n",
    "### Reading a FITS Fiile: Crab Nebula and Pulsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ipiBNEX9WmL"
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# FITS sample file used from Chandra X-Ray Observatory:\n",
    "# http://chandra.harvard.edu/photo/2009/crab/fits/crab.fits\n",
    "image_file = fits.open('http://chandra.harvard.edu/photo/2009/crab/fits/crab.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNHGe0349yTG"
   },
   "source": [
    "Our image file contains headers and data combined. Let's look at the header information first.\n",
    "\n",
    "### FITS Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mESDdmi9943l"
   },
   "outputs": [],
   "source": [
    "image_file[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyOF5DCr96r8"
   },
   "outputs": [],
   "source": [
    "image_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4gTqvn398qZ"
   },
   "outputs": [],
   "source": [
    "image_data = image_file[0].data\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TFR0o0M-Cn9"
   },
   "source": [
    "### Plotting with AstroPy\n",
    "\n",
    "Here, we will use matplotlib in conjunction with AstroPy to visualize this Nebula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nooB3qYG-j5Z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "plt.style.use(astropy_mpl_style)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image_data, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJemDmy2-o31"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image_data, cmap='plasma')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHzfRBTuAa4o"
   },
   "source": [
    "You can also create a FITS file from a NumPy array using the following template:\n",
    "\n",
    "```python\n",
    "hdu = fits.PrimaryHDU(new_data)\n",
    "hdu.writeto('filename.fits')\n",
    "```\n",
    "\n",
    "The metadata can be added in later, but with the PrimaryHDU function, it goes ahead and fills some of that data in for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BxpYzmsqZhq"
   },
   "source": [
    "## 3c. Engineering Applications (Signal Processing, Streamed Data, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal processing is one example of an engineering application that would take a specific data format and require one to manipulate or modify the data in order to produce desired physical quantities. Let's take for example a sample sine wave for audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sound\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "framerate = 44100\n",
    "t = np.linspace(0,5,framerate*5)\n",
    "data = np.sin(2*np.pi*220*t) # one tone\n",
    "plt.plot(data)\n",
    "data = data + np.sin(2*np.pi*224*t) # two tones (two sine waves)\n",
    "plt.plot(data)\n",
    "plt.xlim(0,1000)\n",
    "Audio(data,rate=framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also do stereo or more channels\n",
    "dataleft = np.sin(2*np.pi*220*t)\n",
    "dataright = np.sin(2*np.pi*224*t)\n",
    "plt.plot(dataleft)\n",
    "plt.plot(dataright)\n",
    "plt.xlim(0,1000)\n",
    "Audio([dataleft, dataright],rate=framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"http://www.nasa.gov/mp3/574928main_houston_problem.mp3\")  # From URL"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "io.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
